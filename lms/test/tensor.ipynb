{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-22 17:03:43.037595: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-22 17:03:43.122507: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-22 17:03:43.122562: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n",
      "60000 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 구성부분\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train=x_train[...,np.newaxis]\n",
    "x_test=x_test[...,np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8823ab4a90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, utils, Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-22 17:04:00.971586: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-22 17:04:00.971636: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-22 17:04:00.971676: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jammy): /proc/driver/nvidia/version does not exist\n",
      "2022-06-22 17:04:00.972922: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f8823afd1b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Conv2D(32,3,activation='relu',input_shape=(None,None,100)))\n",
    "model.add(layers.Conv2D(64,3,activation='relu'))\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Dense(10,activation='softmax'))\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, None, None, 32)    28832     \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, None, None, 64)    18496     \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 64)               0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 47,978\n",
      "Trainable params: 47,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "input_ = np.zeros((10,100,100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = layers.Dense(20)\n",
    "conv1 = layers.Conv2D(32, 3, activation='relu')\n",
    "conv2 = layers.Conv2D(16, 3, activation='relu')\n",
    "flatten = layers.Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 20), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = conv1(input_)\n",
    "x = conv2(x)\n",
    "x = flatten(x)\n",
    "x = linear(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 100, 100, 3) dtype=float32 (created by layer 'input_1')>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ = Input((100,100,3))\n",
    "input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20) dtype=float32 (created by layer 'dense_1')>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = conv1(input_)\n",
    "x = conv2(x)\n",
    "x = flatten(x)\n",
    "x = linear(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "\n",
    "model = Model(inputs=input_, outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 98, 98, 32)        896       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 96, 96, 16)        4624      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 147456)            0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                2949140   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,954,660\n",
      "Trainable params: 2,954,660\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20) dtype=float32 (created by layer 'model')>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 98, 98, 32)        896       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 96, 96, 16)        4624      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 147456)            0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                2949140   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,954,660\n",
      "Trainable params: 2,954,660\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function plot_model in module keras.utils.vis_utils:\n",
      "\n",
      "plot_model(model, to_file='model.png', show_shapes=False, show_dtype=False, show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96, layer_range=None, show_layer_activations=False)\n",
      "    Converts a Keras model to dot format and save to a file.\n",
      "    \n",
      "    Example:\n",
      "    \n",
      "    ```python\n",
      "    input = tf.keras.Input(shape=(100,), dtype='int32', name='input')\n",
      "    x = tf.keras.layers.Embedding(\n",
      "        output_dim=512, input_dim=10000, input_length=100)(input)\n",
      "    x = tf.keras.layers.LSTM(32)(x)\n",
      "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
      "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
      "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
      "    output = tf.keras.layers.Dense(1, activation='sigmoid', name='output')(x)\n",
      "    model = tf.keras.Model(inputs=[input], outputs=[output])\n",
      "    dot_img_file = '/tmp/model_1.png'\n",
      "    tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)\n",
      "    ```\n",
      "    \n",
      "    Args:\n",
      "      model: A Keras model instance\n",
      "      to_file: File name of the plot image.\n",
      "      show_shapes: whether to display shape information.\n",
      "      show_dtype: whether to display layer dtypes.\n",
      "      show_layer_names: whether to display layer names.\n",
      "      rankdir: `rankdir` argument passed to PyDot,\n",
      "          a string specifying the format of the plot: 'TB' creates a vertical\n",
      "            plot; 'LR' creates a horizontal plot.\n",
      "      expand_nested: Whether to expand nested models into clusters.\n",
      "      dpi: Dots per inch.\n",
      "      layer_range: input of `list` containing two `str` items, which is the\n",
      "        starting layer name and ending layer name (both inclusive) indicating the\n",
      "        range of layers for which the plot will be generated. It also accepts\n",
      "        regex patterns instead of exact name. In such case, start predicate will\n",
      "        be the first element it matches to `layer_range[0]` and the end predicate\n",
      "        will be the last element it matches to `layer_range[1]`. By default `None`\n",
      "        which considers all layers of model. Note that you must pass range such\n",
      "        that the resultant subgraph must be complete.\n",
      "      show_layer_activations: Display layer activations (only for layers that\n",
      "        have an `activation` property).\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: if `plot_model` is called before the model is built.\n",
      "    \n",
      "    Returns:\n",
      "      A Jupyter notebook Image object if Jupyter is installed.\n",
      "      This enables in-line display of the model plots in notebooks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "help(plot_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydot\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /home/hchang/myspace/env/lib/python3.10/site-packages (from pydot) (3.0.9)\n",
      "Installing collected packages: pydot\n",
      "Successfully installed pydot-1.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Sequential in module keras.engine.sequential:\n",
      "\n",
      "class Sequential(keras.engine.functional.Functional)\n",
      " |  Sequential(layers=None, name=None)\n",
      " |  \n",
      " |  `Sequential` groups a linear stack of layers into a `tf.keras.Model`.\n",
      " |  \n",
      " |  `Sequential` provides training and inference features on this model.\n",
      " |  \n",
      " |  Examples:\n",
      " |  \n",
      " |  ```python\n",
      " |  # Optionally, the first layer can receive an `input_shape` argument:\n",
      " |  model = tf.keras.Sequential()\n",
      " |  model.add(tf.keras.layers.Dense(8, input_shape=(16,)))\n",
      " |  # Afterwards, we do automatic shape inference:\n",
      " |  model.add(tf.keras.layers.Dense(4))\n",
      " |  \n",
      " |  # This is identical to the following:\n",
      " |  model = tf.keras.Sequential()\n",
      " |  model.add(tf.keras.Input(shape=(16,)))\n",
      " |  model.add(tf.keras.layers.Dense(8))\n",
      " |  \n",
      " |  # Note that you can also omit the `input_shape` argument.\n",
      " |  # In that case the model doesn't have any weights until the first call\n",
      " |  # to a training/evaluation method (since it isn't yet built):\n",
      " |  model = tf.keras.Sequential()\n",
      " |  model.add(tf.keras.layers.Dense(8))\n",
      " |  model.add(tf.keras.layers.Dense(4))\n",
      " |  # model.weights not created yet\n",
      " |  \n",
      " |  # Whereas if you specify the input shape, the model gets built\n",
      " |  # continuously as you are adding layers:\n",
      " |  model = tf.keras.Sequential()\n",
      " |  model.add(tf.keras.layers.Dense(8, input_shape=(16,)))\n",
      " |  model.add(tf.keras.layers.Dense(4))\n",
      " |  len(model.weights)\n",
      " |  # Returns \"4\"\n",
      " |  \n",
      " |  # When using the delayed-build pattern (no input shape specified), you can\n",
      " |  # choose to manually build your model by calling\n",
      " |  # `build(batch_input_shape)`:\n",
      " |  model = tf.keras.Sequential()\n",
      " |  model.add(tf.keras.layers.Dense(8))\n",
      " |  model.add(tf.keras.layers.Dense(4))\n",
      " |  model.build((None, 16))\n",
      " |  len(model.weights)\n",
      " |  # Returns \"4\"\n",
      " |  \n",
      " |  # Note that when using the delayed-build pattern (no input shape specified),\n",
      " |  # the model gets built the first time you call `fit`, `eval`, or `predict`,\n",
      " |  # or the first time you call the model on some input data.\n",
      " |  model = tf.keras.Sequential()\n",
      " |  model.add(tf.keras.layers.Dense(8))\n",
      " |  model.add(tf.keras.layers.Dense(1))\n",
      " |  model.compile(optimizer='sgd', loss='mse')\n",
      " |  # This builds the model for the first time:\n",
      " |  model.fit(x, y, batch_size=32, epochs=10)\n",
      " |  ```\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Sequential\n",
      " |      keras.engine.functional.Functional\n",
      " |      keras.engine.training.Model\n",
      " |      keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.autotrackable.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      keras.utils.version_utils.LayerVersionSelector\n",
      " |      keras.utils.version_utils.ModelVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, layers=None, name=None)\n",
      " |      Creates a `Sequential` model instance.\n",
      " |      \n",
      " |      Args:\n",
      " |        layers: Optional list of layers to add to the model.\n",
      " |        name: Optional name for the model.\n",
      " |  \n",
      " |  add(self, layer)\n",
      " |      Adds a layer instance on top of the layer stack.\n",
      " |      \n",
      " |      Args:\n",
      " |          layer: layer instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          TypeError: If `layer` is not a layer instance.\n",
      " |          ValueError: In case the `layer` argument does not\n",
      " |              know its input shape.\n",
      " |          ValueError: In case the `layer` argument has\n",
      " |              multiple output tensors, or is already connected\n",
      " |              somewhere else (forbidden in `Sequential` models).\n",
      " |  \n",
      " |  build(self, input_shape=None)\n",
      " |      Builds the model based on input shapes received.\n",
      " |      \n",
      " |      This is to be used for subclassed models, which do not know at instantiation\n",
      " |      time what their inputs look like.\n",
      " |      \n",
      " |      This method only exists for users who want to call `model.build()` in a\n",
      " |      standalone way (as a substitute for calling the model on real data to\n",
      " |      build it). It will never be called by the framework (and thus it will\n",
      " |      never throw unexpected errors in an unrelated workflow).\n",
      " |      \n",
      " |      Args:\n",
      " |       input_shape: Single tuple, `TensorShape` instance, or list/dict of shapes,\n",
      " |         where shapes are tuples, integers, or `TensorShape` instances.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError:\n",
      " |          1. In case of invalid user-provided data (not of type tuple,\n",
      " |             list, `TensorShape`, or dict).\n",
      " |          2. If the model requires call arguments that are agnostic\n",
      " |             to the input shapes (positional or keyword arg in call signature).\n",
      " |          3. If not all layers were properly built.\n",
      " |          4. If float type inputs are not supported within the layers.\n",
      " |      \n",
      " |        In each of these cases, the user should build their model by calling it\n",
      " |        on real tensor data.\n",
      " |  \n",
      " |  call(self, inputs, training=None, mask=None)\n",
      " |      Calls the model on new inputs.\n",
      " |      \n",
      " |      In this case `call` just reapplies\n",
      " |      all ops in the graph to the new inputs\n",
      " |      (e.g. build a new computational graph from the provided inputs).\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: A tensor or list of tensors.\n",
      " |          training: Boolean or boolean scalar tensor, indicating whether to run\n",
      " |            the `Network` in training mode or inference mode.\n",
      " |          mask: A mask or list of masks. A mask can be\n",
      " |              either a tensor or None (no mask).\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor if there is a single output, or\n",
      " |          a list of tensors if there are more than one outputs.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      This method will cause the layer's state to be built, if that has not\n",
      " |      happened before. This requires that the layer will later be used with\n",
      " |      inputs that match the input shape provided here.\n",
      " |      \n",
      " |      Args:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the `Model`.\n",
      " |      \n",
      " |      Config is a Python dictionary (serializable) containing the configuration of\n",
      " |      an object, which in this case is a `Model`. This allows the `Model` to be\n",
      " |      be reinstantiated later (without its trained weights) from this\n",
      " |      configuration.\n",
      " |      \n",
      " |      Note that `get_config()` does not guarantee to return a fresh copy of dict\n",
      " |      every time it is called. The callers should make a copy of the returned dict\n",
      " |      if they want to modify it.\n",
      " |      \n",
      " |      Developers of subclassed `Model` are advised to override this method, and\n",
      " |      continue to update the dict from `super(MyModel, self).get_config()`\n",
      " |      to provide the proper configuration of this `Model`. The default config\n",
      " |      is an empty dict. Optionally, raise `NotImplementedError` to allow Keras to\n",
      " |      attempt a default serialization.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary containing the configuration of this `Model`.\n",
      " |  \n",
      " |  pop(self)\n",
      " |      Removes the last layer in the model.\n",
      " |      \n",
      " |      Raises:\n",
      " |          TypeError: if there are no layers in the model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_config(config, custom_objects=None) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Args:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  layers\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  input_spec\n",
      " |      `InputSpec` instance(s) describing the input format for this layer.\n",
      " |      \n",
      " |      When you create a layer subclass, you can set `self.input_spec` to enable\n",
      " |      the layer to run input compatibility checks when it is called.\n",
      " |      Consider a `Conv2D` layer: it can only be called on a single input tensor\n",
      " |      of rank 4. As such, you can set, in `__init__()`:\n",
      " |      \n",
      " |      ```python\n",
      " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
      " |      ```\n",
      " |      \n",
      " |      Now, if you try to call the layer on an input that isn't rank 4\n",
      " |      (for instance, an input of shape `(2,)`, it will raise a nicely-formatted\n",
      " |      error:\n",
      " |      \n",
      " |      ```\n",
      " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
      " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
      " |      ```\n",
      " |      \n",
      " |      Input checks that can be specified via `input_spec` include:\n",
      " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
      " |      - Shape\n",
      " |      - Rank (ndim)\n",
      " |      - Dtype\n",
      " |      \n",
      " |      For more information, see `tf.keras.layers.InputSpec`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from keras.engine.functional.Functional:\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.training.Model:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |  \n",
      " |  __copy__(self)\n",
      " |  \n",
      " |  __deepcopy__(self, memo)\n",
      " |  \n",
      " |  __reduce__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  compile(self, optimizer='rmsprop', loss=None, metrics=None, loss_weights=None, weighted_metrics=None, run_eagerly=None, steps_per_execution=None, jit_compile=None, **kwargs)\n",
      " |      Configures the model for training.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
      " |                    loss=tf.keras.losses.BinaryCrossentropy(),\n",
      " |                    metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
      " |                             tf.keras.metrics.FalseNegatives()])\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |          optimizer: String (name of optimizer) or optimizer instance. See\n",
      " |            `tf.keras.optimizers`.\n",
      " |          loss: Loss function. May be a string (name of loss function), or\n",
      " |            a `tf.keras.losses.Loss` instance. See `tf.keras.losses`. A loss\n",
      " |            function is any callable with the signature `loss = fn(y_true,\n",
      " |            y_pred)`, where `y_true` are the ground truth values, and\n",
      " |            `y_pred` are the model's predictions.\n",
      " |            `y_true` should have shape\n",
      " |            `(batch_size, d0, .. dN)` (except in the case of\n",
      " |            sparse loss functions such as\n",
      " |            sparse categorical crossentropy which expects integer arrays of shape\n",
      " |            `(batch_size, d0, .. dN-1)`).\n",
      " |            `y_pred` should have shape `(batch_size, d0, .. dN)`.\n",
      " |            The loss function should return a float tensor.\n",
      " |            If a custom `Loss` instance is\n",
      " |            used and reduction is set to `None`, return value has shape\n",
      " |            `(batch_size, d0, .. dN-1)` i.e. per-sample or per-timestep loss\n",
      " |            values; otherwise, it is a scalar. If the model has multiple outputs,\n",
      " |            you can use a different loss on each output by passing a dictionary\n",
      " |            or a list of losses. The loss value that will be minimized by the\n",
      " |            model will then be the sum of all individual losses, unless\n",
      " |            `loss_weights` is specified.\n",
      " |          metrics: List of metrics to be evaluated by the model during training\n",
      " |            and testing. Each of this can be a string (name of a built-in\n",
      " |            function), function or a `tf.keras.metrics.Metric` instance. See\n",
      " |            `tf.keras.metrics`. Typically you will use `metrics=['accuracy']`. A\n",
      " |            function is any callable with the signature `result = fn(y_true,\n",
      " |            y_pred)`. To specify different metrics for different outputs of a\n",
      " |            multi-output model, you could also pass a dictionary, such as\n",
      " |            `metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`.\n",
      " |            You can also pass a list to specify a metric or a list of metrics\n",
      " |            for each output, such as `metrics=[['accuracy'], ['accuracy', 'mse']]`\n",
      " |            or `metrics=['accuracy', ['accuracy', 'mse']]`. When you pass the\n",
      " |            strings 'accuracy' or 'acc', we convert this to one of\n",
      " |            `tf.keras.metrics.BinaryAccuracy`,\n",
      " |            `tf.keras.metrics.CategoricalAccuracy`,\n",
      " |            `tf.keras.metrics.SparseCategoricalAccuracy` based on the loss\n",
      " |            function used and the model output shape. We do a similar\n",
      " |            conversion for the strings 'crossentropy' and 'ce' as well.\n",
      " |          loss_weights: Optional list or dictionary specifying scalar coefficients\n",
      " |            (Python floats) to weight the loss contributions of different model\n",
      " |            outputs. The loss value that will be minimized by the model will then\n",
      " |            be the *weighted sum* of all individual losses, weighted by the\n",
      " |            `loss_weights` coefficients.\n",
      " |              If a list, it is expected to have a 1:1 mapping to the model's\n",
      " |                outputs. If a dict, it is expected to map output names (strings)\n",
      " |                to scalar coefficients.\n",
      " |          weighted_metrics: List of metrics to be evaluated and weighted by\n",
      " |            `sample_weight` or `class_weight` during training and testing.\n",
      " |          run_eagerly: Bool. Defaults to `False`. If `True`, this `Model`'s\n",
      " |            logic will not be wrapped in a `tf.function`. Recommended to leave\n",
      " |            this as `None` unless your `Model` cannot be run inside a\n",
      " |            `tf.function`. `run_eagerly=True` is not supported when using\n",
      " |            `tf.distribute.experimental.ParameterServerStrategy`.\n",
      " |          steps_per_execution: Int. Defaults to 1. The number of batches to run\n",
      " |            during each `tf.function` call. Running multiple batches inside a\n",
      " |            single `tf.function` call can greatly improve performance on TPUs or\n",
      " |            small models with a large Python overhead. At most, one full epoch\n",
      " |            will be run each execution. If a number larger than the size of the\n",
      " |            epoch is passed, the execution will be truncated to the size of the\n",
      " |            epoch. Note that if `steps_per_execution` is set to `N`,\n",
      " |            `Callback.on_batch_begin` and `Callback.on_batch_end` methods will\n",
      " |            only be called every `N` batches (i.e. before/after each `tf.function`\n",
      " |            execution).\n",
      " |          jit_compile: If `True`, compile the model training step with XLA.\n",
      " |            [XLA](https://www.tensorflow.org/xla) is an optimizing compiler for\n",
      " |            machine learning.\n",
      " |            `jit_compile` is not enabled for by default.\n",
      " |            This option cannot be enabled with `run_eagerly=True`.\n",
      " |            Note that `jit_compile=True` is\n",
      " |            may not necessarily work for all models.\n",
      " |            For more information on supported operations please refer to the\n",
      " |            [XLA documentation](https://www.tensorflow.org/xla).\n",
      " |            Also refer to\n",
      " |            [known XLA issues](https://www.tensorflow.org/xla/known_issues) for\n",
      " |            more details.\n",
      " |          **kwargs: Arguments supported for backwards compatibility only.\n",
      " |  \n",
      " |  compute_loss(self, x=None, y=None, y_pred=None, sample_weight=None)\n",
      " |      Compute the total loss, validate it, and return it.\n",
      " |      \n",
      " |      Subclasses can optionally override this method to provide custom loss\n",
      " |      computation logic.\n",
      " |      \n",
      " |      Example:\n",
      " |      ```python\n",
      " |      class MyModel(tf.keras.Model):\n",
      " |      \n",
      " |        def __init__(self, *args, **kwargs):\n",
      " |          super(MyModel, self).__init__(*args, **kwargs)\n",
      " |          self.loss_tracker = tf.keras.metrics.Mean(name='loss')\n",
      " |      \n",
      " |        def compute_loss(self, x, y, y_pred, sample_weight):\n",
      " |          loss = tf.reduce_mean(tf.math.squared_difference(y_pred, y))\n",
      " |          loss += tf.add_n(self.losses)\n",
      " |          self.loss_tracker.update_state(loss)\n",
      " |          return loss\n",
      " |      \n",
      " |        def reset_metrics(self):\n",
      " |          self.loss_tracker.reset_states()\n",
      " |      \n",
      " |        @property\n",
      " |        def metrics(self):\n",
      " |          return [self.loss_tracker]\n",
      " |      \n",
      " |      tensors = tf.random.uniform((10, 10)), tf.random.uniform((10,))\n",
      " |      dataset = tf.data.Dataset.from_tensor_slices(tensors).repeat().batch(1)\n",
      " |      \n",
      " |      inputs = tf.keras.layers.Input(shape=(10,), name='my_input')\n",
      " |      outputs = tf.keras.layers.Dense(10)(inputs)\n",
      " |      model = MyModel(inputs, outputs)\n",
      " |      model.add_loss(tf.reduce_sum(outputs))\n",
      " |      \n",
      " |      optimizer = tf.keras.optimizers.SGD()\n",
      " |      model.compile(optimizer, loss='mse', steps_per_execution=10)\n",
      " |      model.fit(dataset, epochs=2, steps_per_epoch=10)\n",
      " |      print('My custom loss: ', model.loss_tracker.result().numpy())\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        x: Input data.\n",
      " |        y: Target data.\n",
      " |        y_pred: Predictions returned by the model (output of `model(x)`)\n",
      " |        sample_weight: Sample weights for weighting the loss function.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The total loss as a `tf.Tensor`, or `None` if no loss results (which is\n",
      " |        the case when called by `Model.test_step`).\n",
      " |  \n",
      " |  compute_metrics(self, x, y, y_pred, sample_weight)\n",
      " |      Update metric states and collect all metrics to be returned.\n",
      " |      \n",
      " |      Subclasses can optionally override this method to provide custom metric\n",
      " |      updating and collection logic.\n",
      " |      \n",
      " |      Example:\n",
      " |      ```python\n",
      " |      class MyModel(tf.keras.Sequential):\n",
      " |      \n",
      " |        def compute_metrics(self, x, y, y_pred, sample_weight):\n",
      " |      \n",
      " |          # This super call updates `self.compiled_metrics` and returns results\n",
      " |          # for all metrics listed in `self.metrics`.\n",
      " |          metric_results = super(MyModel, self).compute_metrics(\n",
      " |              x, y, y_pred, sample_weight)\n",
      " |      \n",
      " |          # Note that `self.custom_metric` is not listed in `self.metrics`.\n",
      " |          self.custom_metric.update_state(x, y, y_pred, sample_weight)\n",
      " |          metric_results['custom_metric_name'] = self.custom_metric.result()\n",
      " |          return metric_results\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        x: Input data.\n",
      " |        y: Target data.\n",
      " |        y_pred: Predictions returned by the model (output of `model.call(x)`)\n",
      " |        sample_weight: Sample weights for weighting the loss function.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `dict` containing values that will be passed to\n",
      " |        `tf.keras.callbacks.CallbackList.on_train_batch_end()`. Typically, the\n",
      " |        values of the metrics listed in `self.metrics` are returned. Example:\n",
      " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
      " |  \n",
      " |  evaluate(self, x=None, y=None, batch_size=None, verbose='auto', sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, return_dict=False, **kwargs)\n",
      " |      Returns the loss value & metrics values for the model in test mode.\n",
      " |      \n",
      " |      Computation is done in batches (see the `batch_size` arg.)\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset. Should return a tuple\n",
      " |              of either `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
      " |              or `(inputs, targets, sample_weights)`.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
      " |            for iterator-like inputs` section of `Model.fit`.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely). If\n",
      " |            `x` is a dataset, generator or `keras.utils.Sequence` instance, `y`\n",
      " |            should not be specified (since targets will be obtained from the\n",
      " |            iterator/dataset).\n",
      " |          batch_size: Integer or `None`. Number of samples per batch of\n",
      " |            computation. If unspecified, `batch_size` will default to 32. Do not\n",
      " |            specify the `batch_size` if your data is in the form of a dataset,\n",
      " |            generators, or `keras.utils.Sequence` instances (since they generate\n",
      " |            batches).\n",
      " |          verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = single line.\n",
      " |              `\"auto\"` defaults to 1 for most cases, and to 2 when used with\n",
      " |              `ParameterServerStrategy`. Note that the progress bar is not\n",
      " |              particularly useful when logged to a file, so `verbose=2` is\n",
      " |              recommended when not running interactively (e.g. in a production\n",
      " |              environment).\n",
      " |          sample_weight: Optional Numpy array of weights for the test samples,\n",
      " |            used for weighting the loss function. You can either pass a flat (1D)\n",
      " |            Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples), or in the case of\n",
      " |                temporal data, you can pass a 2D array with shape `(samples,\n",
      " |                sequence_length)`, to apply a different weight to every timestep\n",
      " |                of every sample. This argument is not supported when `x` is a\n",
      " |                dataset, instead pass sample weights as the third element of `x`.\n",
      " |          steps: Integer or `None`. Total number of steps (batches of samples)\n",
      " |            before declaring the evaluation round finished. Ignored with the\n",
      " |            default value of `None`. If x is a `tf.data` dataset and `steps` is\n",
      " |            None, 'evaluate' will run until the dataset is exhausted. This\n",
      " |            argument is not supported with array inputs.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances. List of\n",
      " |            callbacks to apply during evaluation. See\n",
      " |            [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |            input only. Maximum size for the generator queue. If unspecified,\n",
      " |            `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |            only. Maximum number of processes to spin up when using process-based\n",
      " |            threading. If unspecified, `workers` will default to 1.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |            `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |            threading. If unspecified, `use_multiprocessing` will default to\n",
      " |            `False`. Note that because this implementation relies on\n",
      " |            multiprocessing, you should not pass non-picklable arguments to the\n",
      " |            generator as they can't be passed easily to children processes.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
      " |            with each key being the name of the metric. If `False`, they are\n",
      " |            returned as a list.\n",
      " |          **kwargs: Unused at this time.\n",
      " |      \n",
      " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
      " |      `Model.fit`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.evaluate` is wrapped in a `tf.function`.\n",
      " |  \n",
      " |  evaluate_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Evaluates the model on a data generator.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.evaluate` now supports generators, so there is no longer any need\n",
      " |        to use this endpoint.\n",
      " |  \n",
      " |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose='auto', callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_batch_size=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Trains the model for a fixed number of epochs (iterations on a dataset).\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset. Should return a tuple\n",
      " |              of either `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
      " |              or `(inputs, targets, sample_weights)`.\n",
      " |            - A `tf.keras.utils.experimental.DatasetCreator`, which wraps a\n",
      " |              callable that takes a single argument of type\n",
      " |              `tf.distribute.InputContext`, and returns a `tf.data.Dataset`.\n",
      " |              `DatasetCreator` should be used when users prefer to specify the\n",
      " |              per-replica batching and sharding logic for the `Dataset`.\n",
      " |              See `tf.keras.utils.experimental.DatasetCreator` doc for more\n",
      " |              information.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given below. If using\n",
      " |            `tf.distribute.experimental.ParameterServerStrategy`, only\n",
      " |            `DatasetCreator` type is supported for `x`.\n",
      " |          y: Target data. Like the input data `x`,\n",
      " |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      " |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
      " |            tensor targets, or inversely). If `x` is a dataset, generator,\n",
      " |            or `keras.utils.Sequence` instance, `y` should\n",
      " |            not be specified (since targets will be obtained from `x`).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          epochs: Integer. Number of epochs to train the model.\n",
      " |              An epoch is an iteration over the entire `x` and `y`\n",
      " |              data provided\n",
      " |              (unless the `steps_per_epoch` flag is set to\n",
      " |              something other than None).\n",
      " |              Note that in conjunction with `initial_epoch`,\n",
      " |              `epochs` is to be understood as \"final epoch\".\n",
      " |              The model is not trained for a number of iterations\n",
      " |              given by `epochs`, but merely until the epoch\n",
      " |              of index `epochs` is reached.\n",
      " |          verbose: 'auto', 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      " |              'auto' defaults to 1 for most cases, but 2 when used with\n",
      " |              `ParameterServerStrategy`. Note that the progress bar is not\n",
      " |              particularly useful when logged to a file, so verbose=2 is\n",
      " |              recommended when not running interactively (eg, in a production\n",
      " |              environment).\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training.\n",
      " |              See `tf.keras.callbacks`. Note `tf.keras.callbacks.ProgbarLogger`\n",
      " |              and `tf.keras.callbacks.History` callbacks are created automatically\n",
      " |              and need not be passed into `model.fit`.\n",
      " |              `tf.keras.callbacks.ProgbarLogger` is created or not based on\n",
      " |              `verbose` argument to `model.fit`.\n",
      " |              Callbacks with batch-level calls are currently unsupported with\n",
      " |              `tf.distribute.experimental.ParameterServerStrategy`, and users are\n",
      " |              advised to implement epoch-level calls instead with an appropriate\n",
      " |              `steps_per_epoch` value.\n",
      " |          validation_split: Float between 0 and 1.\n",
      " |              Fraction of the training data to be used as validation data.\n",
      " |              The model will set apart this fraction of the training data,\n",
      " |              will not train on it, and will evaluate\n",
      " |              the loss and any model metrics\n",
      " |              on this data at the end of each epoch.\n",
      " |              The validation data is selected from the last samples\n",
      " |              in the `x` and `y` data provided, before shuffling. This argument is\n",
      " |              not supported when `x` is a dataset, generator or\n",
      " |              `keras.utils.Sequence` instance.\n",
      " |              If both `validation_data` and `validation_split` are provided,\n",
      " |              `validation_data` will override `validation_split`.\n",
      " |              `validation_split` is not yet supported with\n",
      " |              `tf.distribute.experimental.ParameterServerStrategy`.\n",
      " |          validation_data: Data on which to evaluate\n",
      " |              the loss and any model metrics at the end of each epoch.\n",
      " |              The model will not be trained on this data. Thus, note the fact\n",
      " |              that the validation loss of data provided using `validation_split`\n",
      " |              or `validation_data` is not affected by regularization layers like\n",
      " |              noise and dropout.\n",
      " |              `validation_data` will override `validation_split`.\n",
      " |              `validation_data` could be:\n",
      " |                - A tuple `(x_val, y_val)` of Numpy arrays or tensors.\n",
      " |                - A tuple `(x_val, y_val, val_sample_weights)` of NumPy arrays.\n",
      " |                - A `tf.data.Dataset`.\n",
      " |                - A Python generator or `keras.utils.Sequence` returning\n",
      " |                `(inputs, targets)` or `(inputs, targets, sample_weights)`.\n",
      " |              `validation_data` is not yet supported with\n",
      " |              `tf.distribute.experimental.ParameterServerStrategy`.\n",
      " |          shuffle: Boolean (whether to shuffle the training data\n",
      " |              before each epoch) or str (for 'batch'). This argument is ignored\n",
      " |              when `x` is a generator or an object of tf.data.Dataset.\n",
      " |              'batch' is a special option for dealing\n",
      " |              with the limitations of HDF5 data; it shuffles in batch-sized\n",
      " |              chunks. Has no effect when `steps_per_epoch` is not `None`.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |              to a weight (float) value, used for weighting the loss function\n",
      " |              (during training only).\n",
      " |              This can be useful to tell the model to\n",
      " |              \"pay more attention\" to samples from\n",
      " |              an under-represented class.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the training samples, used for weighting the loss function\n",
      " |              (during training only). You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample. This\n",
      " |              argument is not supported when `x` is a dataset, generator, or\n",
      " |             `keras.utils.Sequence` instance, instead provide the sample_weights\n",
      " |              as the third element of `x`.\n",
      " |          initial_epoch: Integer.\n",
      " |              Epoch at which to start training\n",
      " |              (useful for resuming a previous training run).\n",
      " |          steps_per_epoch: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring one epoch finished and starting the\n",
      " |              next epoch. When training with input tensors such as\n",
      " |              TensorFlow data tensors, the default `None` is equal to\n",
      " |              the number of samples in your dataset divided by\n",
      " |              the batch size, or 1 if that cannot be determined. If x is a\n",
      " |              `tf.data` dataset, and 'steps_per_epoch'\n",
      " |              is None, the epoch will run until the input dataset is exhausted.\n",
      " |              When passing an infinitely repeating dataset, you must specify the\n",
      " |              `steps_per_epoch` argument. If `steps_per_epoch=-1` the training\n",
      " |              will run indefinitely with an infinitely repeating dataset.\n",
      " |              This argument is not supported with array inputs.\n",
      " |              When using `tf.distribute.experimental.ParameterServerStrategy`:\n",
      " |                * `steps_per_epoch=None` is not supported.\n",
      " |          validation_steps: Only relevant if `validation_data` is provided and\n",
      " |              is a `tf.data` dataset. Total number of steps (batches of\n",
      " |              samples) to draw before stopping when performing validation\n",
      " |              at the end of every epoch. If 'validation_steps' is None, validation\n",
      " |              will run until the `validation_data` dataset is exhausted. In the\n",
      " |              case of an infinitely repeated dataset, it will run into an\n",
      " |              infinite loop. If 'validation_steps' is specified and only part of\n",
      " |              the dataset will be consumed, the evaluation will start from the\n",
      " |              beginning of the dataset at each epoch. This ensures that the same\n",
      " |              validation samples are used every time.\n",
      " |          validation_batch_size: Integer or `None`.\n",
      " |              Number of samples per validation batch.\n",
      " |              If unspecified, will default to `batch_size`.\n",
      " |              Do not specify the `validation_batch_size` if your data is in the\n",
      " |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          validation_freq: Only relevant if validation data is provided. Integer\n",
      " |              or `collections.abc.Container` instance (e.g. list, tuple, etc.).\n",
      " |              If an integer, specifies how many training epochs to run before a\n",
      " |              new validation run is performed, e.g. `validation_freq=2` runs\n",
      " |              validation every 2 epochs. If a Container, specifies the epochs on\n",
      " |              which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
      " |              validation at the end of the 1st, 2nd, and 10th epochs.\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up\n",
      " |              when using process-based threading. If unspecified, `workers`\n",
      " |              will default to 1.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      Unpacking behavior for iterator-like inputs:\n",
      " |          A common pattern is to pass a tf.data.Dataset, generator, or\n",
      " |        tf.keras.utils.Sequence to the `x` argument of fit, which will in fact\n",
      " |        yield not only features (x) but optionally targets (y) and sample weights.\n",
      " |        Keras requires that the output of such iterator-likes be unambiguous. The\n",
      " |        iterator should return a tuple of length 1, 2, or 3, where the optional\n",
      " |        second and third elements will be used for y and sample_weight\n",
      " |        respectively. Any other type provided will be wrapped in a length one\n",
      " |        tuple, effectively treating everything as 'x'. When yielding dicts, they\n",
      " |        should still adhere to the top-level tuple structure.\n",
      " |        e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
      " |        features, targets, and weights from the keys of a single dict.\n",
      " |          A notable unsupported data type is the namedtuple. The reason is that\n",
      " |        it behaves like both an ordered datatype (tuple) and a mapping\n",
      " |        datatype (dict). So given a namedtuple of the form:\n",
      " |            `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
      " |        it is ambiguous whether to reverse the order of the elements when\n",
      " |        interpreting the value. Even worse is a tuple of the form:\n",
      " |            `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
      " |        where it is unclear if the tuple was intended to be unpacked into x, y,\n",
      " |        and sample_weight or passed through as a single element to `x`. As a\n",
      " |        result the data processing code will simply raise a ValueError if it\n",
      " |        encounters a namedtuple. (Along with instructions to remedy the issue.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `History` object. Its `History.history` attribute is\n",
      " |          a record of training loss values and metrics values\n",
      " |          at successive epochs, as well as validation loss values\n",
      " |          and validation metrics values (if applicable).\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: 1. If the model was never compiled or,\n",
      " |          2. If `model.fit` is  wrapped in `tf.function`.\n",
      " |      \n",
      " |          ValueError: In case of mismatch between the provided input data\n",
      " |              and what the model expects or when the input data is empty.\n",
      " |  \n",
      " |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
      " |      Fits the model on data yielded batch-by-batch by a Python generator.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.fit` now supports generators, so there is no longer any need to use\n",
      " |        this endpoint.\n",
      " |  \n",
      " |  get_layer(self, name=None, index=None)\n",
      " |      Retrieves a layer based on either its name (unique) or index.\n",
      " |      \n",
      " |      If `name` and `index` are both provided, `index` will take precedence.\n",
      " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
      " |      \n",
      " |      Args:\n",
      " |          name: String, name of layer.\n",
      " |          index: Integer, index of layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Retrieves the weights of the model.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A flat list of Numpy arrays.\n",
      " |  \n",
      " |  load_weights(self, filepath, by_name=False, skip_mismatch=False, options=None)\n",
      " |      Loads all layer weights, either from a TensorFlow or an HDF5 weight file.\n",
      " |      \n",
      " |      If `by_name` is False weights are loaded based on the network's\n",
      " |      topology. This means the architecture should be the same as when the weights\n",
      " |      were saved.  Note that layers that don't have weights are not taken into\n",
      " |      account in the topological ordering, so adding or removing layers is fine as\n",
      " |      long as they don't have weights.\n",
      " |      \n",
      " |      If `by_name` is True, weights are loaded into layers only if they share the\n",
      " |      same name. This is useful for fine-tuning or transfer-learning models where\n",
      " |      some of the layers have changed.\n",
      " |      \n",
      " |      Only topological loading (`by_name=False`) is supported when loading weights\n",
      " |      from the TensorFlow format. Note that topological loading differs slightly\n",
      " |      between TensorFlow and HDF5 formats for user-defined classes inheriting from\n",
      " |      `tf.keras.Model`: HDF5 loads based on a flattened list of weights, while the\n",
      " |      TensorFlow format loads based on the object-local names of attributes to\n",
      " |      which layers are assigned in the `Model`'s constructor.\n",
      " |      \n",
      " |      Args:\n",
      " |          filepath: String, path to the weights file to load. For weight files in\n",
      " |              TensorFlow format, this is the file prefix (the same as was passed\n",
      " |              to `save_weights`). This can also be a path to a SavedModel\n",
      " |              saved from `model.save`.\n",
      " |          by_name: Boolean, whether to load weights by name or by topological\n",
      " |              order. Only topological loading is supported for weight files in\n",
      " |              TensorFlow format.\n",
      " |          skip_mismatch: Boolean, whether to skip loading of layers where there is\n",
      " |              a mismatch in the number of weights, or a mismatch in the shape of\n",
      " |              the weight (only valid when `by_name=True`).\n",
      " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
      " |              options for loading weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          When loading a weight file in TensorFlow format, returns the same status\n",
      " |          object as `tf.train.Checkpoint.restore`. When graph building, restore\n",
      " |          ops are run automatically as soon as the network is built (on first call\n",
      " |          for user-defined classes inheriting from `Model`, immediately if it is\n",
      " |          already built).\n",
      " |      \n",
      " |          When loading weights in HDF5 format, returns `None`.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: If `h5py` is not available and the weight file is in HDF5\n",
      " |              format.\n",
      " |          ValueError: If `skip_mismatch` is set to `True` when `by_name` is\n",
      " |            `False`.\n",
      " |  \n",
      " |  make_predict_function(self, force=False)\n",
      " |      Creates a function that executes one step of inference.\n",
      " |      \n",
      " |      This method can be overridden to support custom inference logic.\n",
      " |      This method is called by `Model.predict` and `Model.predict_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
      " |      logic to `Model.predict_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.predict` or\n",
      " |      `Model.predict_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called. You can skip the cache and generate again the\n",
      " |      function with `force=True`.\n",
      " |      \n",
      " |      Args:\n",
      " |        force: Whether to regenerate the predict function and skip the cached\n",
      " |          function if available.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return the outputs of the `Model`.\n",
      " |  \n",
      " |  make_test_function(self, force=False)\n",
      " |      Creates a function that executes one step of evaluation.\n",
      " |      \n",
      " |      This method can be overridden to support custom evaluation logic.\n",
      " |      This method is called by `Model.evaluate` and `Model.test_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
      " |      logic to `Model.test_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.evaluate` or\n",
      " |      `Model.test_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called. You can skip the cache and generate again the\n",
      " |      function with `force=True`.\n",
      " |      \n",
      " |      Args:\n",
      " |        force: Whether to regenerate the test function and skip the cached\n",
      " |          function if available.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
      " |        be passed to `tf.keras.Callbacks.on_test_batch_end`.\n",
      " |  \n",
      " |  make_train_function(self, force=False)\n",
      " |      Creates a function that executes one step of training.\n",
      " |      \n",
      " |      This method can be overridden to support custom training logic.\n",
      " |      This method is called by `Model.fit` and `Model.train_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual training\n",
      " |      logic to `Model.train_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.fit` or\n",
      " |      `Model.train_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called. You can skip the cache and generate again the\n",
      " |      function with `force=True`.\n",
      " |      \n",
      " |      Args:\n",
      " |        force: Whether to regenerate the train function and skip the cached\n",
      " |          function if available.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
      " |        be passed to `tf.keras.Callbacks.on_train_batch_end`, such as\n",
      " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
      " |  \n",
      " |  predict(self, x, batch_size=None, verbose='auto', steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Generates output predictions for the input samples.\n",
      " |      \n",
      " |      Computation is done in batches. This method is designed for batch processing\n",
      " |      of large numbers of inputs. It is not intended for use inside of loops\n",
      " |      that iterate over your data and process small numbers of inputs at a time.\n",
      " |      \n",
      " |      For small numbers of inputs that fit in one batch,\n",
      " |      directly use `__call__()` for faster execution, e.g.,\n",
      " |      `model(x)`, or `model(x, training=False)` if you have layers such as\n",
      " |      `tf.keras.layers.BatchNormalization` that behave differently during\n",
      " |      inference. You may pair the individual model call with a `tf.function`\n",
      " |      for additional performance inside your inner loop.\n",
      " |      If you need access to numpy array values instead of tensors after your\n",
      " |      model call, you can use `tensor.numpy()` to get the numpy array value of\n",
      " |      an eager tensor.\n",
      " |      \n",
      " |      Also, note the fact that test loss is not affected by\n",
      " |      regularization layers like noise and dropout.\n",
      " |      \n",
      " |      Note: See [this FAQ entry](\n",
      " |      https://keras.io/getting_started/faq/#whats-the-difference-between-model-methods-predict-and-call)\n",
      " |      for more details about the difference between `Model` methods `predict()`\n",
      " |      and `__call__()`.\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input samples. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A `tf.data` dataset.\n",
      " |            - A generator or `keras.utils.Sequence` instance.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
      " |            for iterator-like inputs` section of `Model.fit`.\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per batch.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of dataset, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = single line.\n",
      " |              `\"auto\"` defaults to 1 for most cases, and to 2 when used with\n",
      " |              `ParameterServerStrategy`. Note that the progress bar is not\n",
      " |              particularly useful when logged to a file, so `verbose=2` is\n",
      " |              recommended when not running interactively (e.g. in a production\n",
      " |              environment).\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              before declaring the prediction round finished.\n",
      " |              Ignored with the default value of `None`. If x is a `tf.data`\n",
      " |              dataset and `steps` is None, `predict()` will\n",
      " |              run until the input dataset is exhausted.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during prediction.\n",
      " |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up when using\n",
      " |              process-based threading. If unspecified, `workers` will default\n",
      " |              to 1.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
      " |      `Model.fit`. Note that Model.predict uses the same interpretation rules as\n",
      " |      `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for all\n",
      " |      three methods.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.predict` is wrapped in a `tf.function`.\n",
      " |          ValueError: In case of mismatch between the provided\n",
      " |              input data and the model's expectations,\n",
      " |              or in case a stateful model receives a number of samples\n",
      " |              that is not a multiple of the batch size.\n",
      " |  \n",
      " |  predict_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Generates predictions for the input samples from a data generator.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.predict` now supports generators, so there is no longer any need\n",
      " |        to use this endpoint.\n",
      " |  \n",
      " |  predict_on_batch(self, x)\n",
      " |      Returns predictions for a single batch of samples.\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays (in case the\n",
      " |                model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors (in case the model has\n",
      " |                multiple inputs).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.predict_on_batch` is wrapped in a `tf.function`.\n",
      " |  \n",
      " |  predict_step(self, data)\n",
      " |      The logic for one inference step.\n",
      " |      \n",
      " |      This method can be overridden to support custom inference logic.\n",
      " |      This method is called by `Model.make_predict_function`.\n",
      " |      \n",
      " |      This method should contain the mathematical logic for one step of inference.\n",
      " |      This typically includes the forward pass.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_predict_function`, which can also be overridden.\n",
      " |      \n",
      " |      Args:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The result of one inference step, typically the output of calling the\n",
      " |        `Model` on data.\n",
      " |  \n",
      " |  reset_metrics(self)\n",
      " |      Resets the state of all the metrics in the model.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> _ = model.fit(x, y, verbose=0)\n",
      " |      >>> assert all(float(m.result()) for m in model.metrics)\n",
      " |      \n",
      " |      >>> model.reset_metrics()\n",
      " |      >>> assert all(float(m.result()) == 0 for m in model.metrics)\n",
      " |  \n",
      " |  reset_states(self)\n",
      " |  \n",
      " |  save(self, filepath, overwrite=True, include_optimizer=True, save_format=None, signatures=None, options=None, save_traces=True)\n",
      " |      Saves the model to Tensorflow SavedModel or a single HDF5 file.\n",
      " |      \n",
      " |      Please see `tf.keras.models.save_model` or the\n",
      " |      [Serialization and Saving guide](https://keras.io/guides/serialization_and_saving/)\n",
      " |      for details.\n",
      " |      \n",
      " |      Args:\n",
      " |          filepath: String, PathLike, path to SavedModel or H5 file to save the\n",
      " |              model.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          include_optimizer: If True, save optimizer's state together.\n",
      " |          save_format: Either `'tf'` or `'h5'`, indicating whether to save the\n",
      " |              model to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF 2.X,\n",
      " |              and 'h5' in TF 1.X.\n",
      " |          signatures: Signatures to save with the SavedModel. Applicable to the\n",
      " |              'tf' format only. Please see the `signatures` argument in\n",
      " |              `tf.saved_model.save` for details.\n",
      " |          options: (only applies to SavedModel format)\n",
      " |              `tf.saved_model.SaveOptions` object that specifies options for\n",
      " |              saving to SavedModel.\n",
      " |          save_traces: (only applies to SavedModel format) When enabled, the\n",
      " |              SavedModel will store the function traces for each layer. This\n",
      " |              can be disabled, so that only the configs of each layer are stored.\n",
      " |              Defaults to `True`. Disabling this will decrease serialization time\n",
      " |              and reduce file size, but it requires that all custom layers/models\n",
      " |              implement a `get_config()` method.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      from keras.models import load_model\n",
      " |      \n",
      " |      model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
      " |      del model  # deletes the existing model\n",
      " |      \n",
      " |      # returns a compiled model\n",
      " |      # identical to the previous one\n",
      " |      model = load_model('my_model.h5')\n",
      " |      ```\n",
      " |  \n",
      " |  save_spec(self, dynamic_batch=True)\n",
      " |      Returns the `tf.TensorSpec` of call inputs as a tuple `(args, kwargs)`.\n",
      " |      \n",
      " |      This value is automatically defined after calling the model for the first\n",
      " |      time. Afterwards, you can use it when exporting the model for serving:\n",
      " |      \n",
      " |      ```python\n",
      " |      model = tf.keras.Model(...)\n",
      " |      \n",
      " |      @tf.function\n",
      " |      def serve(*args, **kwargs):\n",
      " |        outputs = model(*args, **kwargs)\n",
      " |        # Apply postprocessing steps, or add additional outputs.\n",
      " |        ...\n",
      " |        return outputs\n",
      " |      \n",
      " |      # arg_specs is `[tf.TensorSpec(...), ...]`. kwarg_specs, in this example, is\n",
      " |      # an empty dict since functional models do not use keyword arguments.\n",
      " |      arg_specs, kwarg_specs = model.save_spec()\n",
      " |      \n",
      " |      model.save(path, signatures={\n",
      " |        'serving_default': serve.get_concrete_function(*arg_specs, **kwarg_specs)\n",
      " |      })\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        dynamic_batch: Whether to set the batch sizes of all the returned\n",
      " |          `tf.TensorSpec` to `None`. (Note that when defining functional or\n",
      " |          Sequential models with `tf.keras.Input([...], batch_size=X)`, the\n",
      " |          batch size will always be preserved). Defaults to `True`.\n",
      " |      Returns:\n",
      " |        If the model inputs are defined, returns a tuple `(args, kwargs)`. All\n",
      " |        elements in `args` and `kwargs` are `tf.TensorSpec`.\n",
      " |        If the model inputs are not defined, returns `None`.\n",
      " |        The model inputs are automatically set when calling the model,\n",
      " |        `model.fit`, `model.evaluate` or `model.predict`.\n",
      " |  \n",
      " |  save_weights(self, filepath, overwrite=True, save_format=None, options=None)\n",
      " |      Saves all layer weights.\n",
      " |      \n",
      " |      Either saves in HDF5 or in TensorFlow format based on the `save_format`\n",
      " |      argument.\n",
      " |      \n",
      " |      When saving in HDF5 format, the weight file has:\n",
      " |        - `layer_names` (attribute), a list of strings\n",
      " |            (ordered names of model layers).\n",
      " |        - For every layer, a `group` named `layer.name`\n",
      " |            - For every such layer group, a group attribute `weight_names`,\n",
      " |                a list of strings\n",
      " |                (ordered names of weights tensor of the layer).\n",
      " |            - For every weight in the layer, a dataset\n",
      " |                storing the weight value, named after the weight tensor.\n",
      " |      \n",
      " |      When saving in TensorFlow format, all objects referenced by the network are\n",
      " |      saved in the same format as `tf.train.Checkpoint`, including any `Layer`\n",
      " |      instances or `Optimizer` instances assigned to object attributes. For\n",
      " |      networks constructed from inputs and outputs using `tf.keras.Model(inputs,\n",
      " |      outputs)`, `Layer` instances used by the network are tracked/saved\n",
      " |      automatically. For user-defined classes which inherit from `tf.keras.Model`,\n",
      " |      `Layer` instances must be assigned to object attributes, typically in the\n",
      " |      constructor. See the documentation of `tf.train.Checkpoint` and\n",
      " |      `tf.keras.Model` for details.\n",
      " |      \n",
      " |      While the formats are the same, do not mix `save_weights` and\n",
      " |      `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be\n",
      " |      loaded using `Model.load_weights`. Checkpoints saved using\n",
      " |      `tf.train.Checkpoint.save` should be restored using the corresponding\n",
      " |      `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over\n",
      " |      `save_weights` for training checkpoints.\n",
      " |      \n",
      " |      The TensorFlow format matches objects and variables by starting at a root\n",
      " |      object, `self` for `save_weights`, and greedily matching attribute\n",
      " |      names. For `Model.save` this is the `Model`, and for `Checkpoint.save` this\n",
      " |      is the `Checkpoint` even if the `Checkpoint` has a model attached. This\n",
      " |      means saving a `tf.keras.Model` using `save_weights` and loading into a\n",
      " |      `tf.train.Checkpoint` with a `Model` attached (or vice versa) will not match\n",
      " |      the `Model`'s variables. See the\n",
      " |      [guide to training checkpoints](https://www.tensorflow.org/guide/checkpoint)\n",
      " |      for details on the TensorFlow format.\n",
      " |      \n",
      " |      Args:\n",
      " |          filepath: String or PathLike, path to the file to save the weights to.\n",
      " |              When saving in TensorFlow format, this is the prefix used for\n",
      " |              checkpoint files (multiple files are generated). Note that the '.h5'\n",
      " |              suffix causes weights to be saved in HDF5 format.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          save_format: Either 'tf' or 'h5'. A `filepath` ending in '.h5' or\n",
      " |              '.keras' will default to HDF5 if `save_format` is `None`. Otherwise\n",
      " |              `None` defaults to 'tf'.\n",
      " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
      " |              options for saving weights.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: If `h5py` is not available when attempting to save in HDF5\n",
      " |              format.\n",
      " |  \n",
      " |  summary(self, line_length=None, positions=None, print_fn=None, expand_nested=False, show_trainable=False)\n",
      " |      Prints a string summary of the network.\n",
      " |      \n",
      " |      Args:\n",
      " |          line_length: Total length of printed lines\n",
      " |              (e.g. set this to adapt the display to different\n",
      " |              terminal window sizes).\n",
      " |          positions: Relative or absolute positions of log elements\n",
      " |              in each line. If not provided,\n",
      " |              defaults to `[.33, .55, .67, 1.]`.\n",
      " |          print_fn: Print function to use. Defaults to `print`.\n",
      " |              It will be called on each line of the summary.\n",
      " |              You can set it to a custom function\n",
      " |              in order to capture the string summary.\n",
      " |          expand_nested: Whether to expand the nested models.\n",
      " |              If not provided, defaults to `False`.\n",
      " |          show_trainable: Whether to show if a layer is trainable.\n",
      " |              If not provided, defaults to `False`.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if `summary()` is called before the model is built.\n",
      " |  \n",
      " |  test_on_batch(self, x, y=None, sample_weight=None, reset_metrics=True, return_dict=False)\n",
      " |      Test the model on a single batch of samples.\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays (in case the\n",
      " |                model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors (in case the model has\n",
      " |                multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors, if\n",
      " |                the model has named inputs.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |            weights to apply to the model's loss for each sample. In the case of\n",
      " |            temporal data, you can pass a 2D array with shape (samples,\n",
      " |            sequence_length), to apply a different weight to every timestep of\n",
      " |            every sample.\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |            batch. If `False`, the metrics will be statefully accumulated across\n",
      " |            batches.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
      " |            with each key being the name of the metric. If `False`, they are\n",
      " |            returned as a list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.test_on_batch` is wrapped in a `tf.function`.\n",
      " |  \n",
      " |  test_step(self, data)\n",
      " |      The logic for one evaluation step.\n",
      " |      \n",
      " |      This method can be overridden to support custom evaluation logic.\n",
      " |      This method is called by `Model.make_test_function`.\n",
      " |      \n",
      " |      This function should contain the mathematical logic for one step of\n",
      " |      evaluation.\n",
      " |      This typically includes the forward pass, loss calculation, and metrics\n",
      " |      updates.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_test_function`, which can also be overridden.\n",
      " |      \n",
      " |      Args:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `dict` containing values that will be passed to\n",
      " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
      " |        values of the `Model`'s metrics are returned.\n",
      " |  \n",
      " |  to_json(self, **kwargs)\n",
      " |      Returns a JSON string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a JSON save file, use\n",
      " |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
      " |      \n",
      " |      Args:\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `json.dumps()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A JSON string.\n",
      " |  \n",
      " |  to_yaml(self, **kwargs)\n",
      " |      Returns a yaml string containing the network configuration.\n",
      " |      \n",
      " |      Note: Since TF 2.6, this method is no longer supported and will raise a\n",
      " |      RuntimeError.\n",
      " |      \n",
      " |      To load a network from a yaml save file, use\n",
      " |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
      " |      \n",
      " |      `custom_objects` should be a dictionary mapping\n",
      " |      the names of custom losses / layers / etc to the corresponding\n",
      " |      functions / classes.\n",
      " |      \n",
      " |      Args:\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `yaml.dump()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A YAML string.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: announces that the method poses a security risk\n",
      " |  \n",
      " |  train_on_batch(self, x, y=None, sample_weight=None, class_weight=None, reset_metrics=True, return_dict=False)\n",
      " |      Runs a single gradient update on a single batch of data.\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |                (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |                (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |                if the model has named inputs.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s).\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |            weights to apply to the model's loss for each sample. In the case of\n",
      " |            temporal data, you can pass a 2D array with shape (samples,\n",
      " |            sequence_length), to apply a different weight to every timestep of\n",
      " |            every sample.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers) to a\n",
      " |            weight (float) to apply to the model's loss for the samples from this\n",
      " |            class during training. This can be useful to tell the model to \"pay\n",
      " |            more attention\" to samples from an under-represented class.\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |            batch. If `False`, the metrics will be statefully accumulated across\n",
      " |            batches.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
      " |            with each key being the name of the metric. If `False`, they are\n",
      " |            returned as a list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar training loss\n",
      " |          (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If `model.train_on_batch` is wrapped in a `tf.function`.\n",
      " |  \n",
      " |  train_step(self, data)\n",
      " |      The logic for one training step.\n",
      " |      \n",
      " |      This method can be overridden to support custom training logic.\n",
      " |      For concrete examples of how to override this method see\n",
      " |      [Customizing what happends in fit](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit).\n",
      " |      This method is called by `Model.make_train_function`.\n",
      " |      \n",
      " |      This method should contain the mathematical logic for one step of training.\n",
      " |      This typically includes the forward pass, loss calculation, backpropagation,\n",
      " |      and metric updates.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_train_function`, which can also be overridden.\n",
      " |      \n",
      " |      Args:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `dict` containing values that will be passed to\n",
      " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
      " |        values of the `Model`'s metrics are returned. Example:\n",
      " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from keras.engine.training.Model:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from keras.engine.training.Model:\n",
      " |  \n",
      " |  distribute_strategy\n",
      " |      The `tf.distribute.Strategy` this model was created under.\n",
      " |  \n",
      " |  metrics\n",
      " |      Returns the model's metrics added using `compile()`, `add_metric()` APIs.\n",
      " |      \n",
      " |      Note: Metrics passed to `compile()` are available only after a `keras.Model`\n",
      " |      has been trained/evaluated on actual data.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      []\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> model.fit(x, y)\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      ['loss', 'mae']\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
      " |      >>> output_1 = d(inputs)\n",
      " |      >>> output_2 = d(inputs)\n",
      " |      >>> model = tf.keras.models.Model(\n",
      " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
      " |      >>> model.add_metric(\n",
      " |      ...    tf.reduce_sum(output_2), name='mean', aggregation='mean')\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
      " |      >>> model.fit(x, (y, y))\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
      " |      'out_1_acc', 'mean']\n",
      " |  \n",
      " |  metrics_names\n",
      " |      Returns the model's display labels for all outputs.\n",
      " |      \n",
      " |      Note: `metrics_names` are available only after a `keras.Model` has been\n",
      " |      trained/evaluated on actual data.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      >>> model.metrics_names\n",
      " |      []\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> model.fit(x, y)\n",
      " |      >>> model.metrics_names\n",
      " |      ['loss', 'mae']\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
      " |      >>> output_1 = d(inputs)\n",
      " |      >>> output_2 = d(inputs)\n",
      " |      >>> model = tf.keras.models.Model(\n",
      " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
      " |      >>> model.fit(x, (y, y))\n",
      " |      >>> model.metrics_names\n",
      " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
      " |      'out_1_acc']\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |      List of all non-trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Non-trainable weights are *not* updated during training. They are expected\n",
      " |      to be updated manually in `call()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of non-trainable variables.\n",
      " |  \n",
      " |  state_updates\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Returns the `updates` from all layers that are stateful.\n",
      " |      \n",
      " |      This is useful for separating training updates and\n",
      " |      state updates, e.g. when we need to update a layer's internal state\n",
      " |      during prediction.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of update ops.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |      List of all trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Trainable weights are updated via gradient descent during training.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of trainable variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
      " |      themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.training.Model:\n",
      " |  \n",
      " |  run_eagerly\n",
      " |      Settable attribute indicating whether the model should run eagerly.\n",
      " |      \n",
      " |      Running eagerly means that your model will be run step by step,\n",
      " |      like Python code. Your model might run slower, but it should become easier\n",
      " |      for you to debug it by stepping into individual layer calls.\n",
      " |      \n",
      " |      By default, we will attempt to compile your model to a static graph to\n",
      " |      deliver the best execution performance.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Boolean, whether the model should run eagerly.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, **kwargs)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(self, inputs):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Activity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      d = tf.keras.layers.Dense(10)\n",
      " |      x = d(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        **kwargs: Used for backwards compatibility only.\n",
      " |  \n",
      " |  add_metric(self, value, name=None, **kwargs)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      This method can be used inside the `call()` method of a subclassed layer\n",
      " |      or model.\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
      " |        def __init__(self):\n",
      " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
      " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
      " |      \n",
      " |        def call(self, inputs):\n",
      " |          self.add_metric(self.mean(inputs))\n",
      " |          self.add_metric(tf.reduce_sum(inputs), name='metric_2')\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any tensor passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      metrics become part of the model's topology and are tracked when you\n",
      " |      save the model via `save()`.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
      " |      Functional Model, as shown in the example below, is not supported. This is\n",
      " |      because we cannot trace the metric result tensor back to the model's inputs.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        name: String metric name.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |          `aggregation` - When the `value` tensor provided is not the result of\n",
      " |          calling a `keras.Metric` instance, it will be aggregated by default\n",
      " |          using a `keras.Metric.Mean`.\n",
      " |  \n",
      " |  add_update(self, updates)\n",
      " |      Add update op(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Args:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregationV2.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The variable created.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  finalize_state(self)\n",
      " |      Finalizes the layers state after updating layer weights.\n",
      " |      \n",
      " |      This function can be subclassed in a layer and will be called after updating\n",
      " |      a layer weights. It can be overridden to finalize any additional layer state\n",
      " |      after a weight update.\n",
      " |      \n",
      " |      This function will be called after weights of a layer have been restored\n",
      " |      from a loaded model.\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first input node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first output node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      sets the weight values from numpy arrays. The weight values should be\n",
      " |      passed in the order they are created by the layer. Note that the layer's\n",
      " |      weights must be instantiated before calling this function, by calling\n",
      " |      the layer.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel matrix\n",
      " |      and the bias vector. These can be used to set the weights of another\n",
      " |      `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Args:\n",
      " |        weights: a list of NumPy arrays. The number\n",
      " |          of arrays and their shape must match\n",
      " |          number of the dimensions of the weights\n",
      " |          of the layer (i.e. it should match the\n",
      " |          output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If the provided weights list does not match the\n",
      " |          layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  compute_dtype\n",
      " |      The dtype of the layer's computations.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
      " |      the weights.\n",
      " |      \n",
      " |      Layers automatically cast their inputs to the compute dtype, which causes\n",
      " |      computations and the output to be in the compute dtype as well. This is done\n",
      " |      by the base Layer class in `Layer.__call__`, so you do not have to insert\n",
      " |      these casts if implementing your own layer.\n",
      " |      \n",
      " |      Layers often perform certain internal computations in higher precision when\n",
      " |      `compute_dtype` is float16 or bfloat16 for numeric stability. The output\n",
      " |      will still typically be float16 or bfloat16 in such cases.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The layer's compute dtype.\n",
      " |  \n",
      " |  dtype\n",
      " |      The dtype of the layer weights.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
      " |      dtype of the layer's computations.\n",
      " |  \n",
      " |  dtype_policy\n",
      " |      The dtype policy associated with this layer.\n",
      " |      \n",
      " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
      " |  \n",
      " |  dynamic\n",
      " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Return Functional API nodes upstream of this layer.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  losses\n",
      " |      List of losses added using the `add_loss()` API.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
      " |      ...   def call(self, inputs):\n",
      " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |      ...     return inputs\n",
      " |      >>> l = MyLayer()\n",
      " |      >>> l(np.ones((10, 1)))\n",
      " |      >>> l.losses\n",
      " |      [1.0]\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Activity regularization.\n",
      " |      >>> len(model.losses)\n",
      " |      0\n",
      " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      >>> len(model.losses)\n",
      " |      1\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
      " |      >>> x = d(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Weight regularization.\n",
      " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      >>> model.losses\n",
      " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  name\n",
      " |      Name of the layer (string), set in the constructor.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Return Functional API nodes downstream of this layer.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variable_dtype\n",
      " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
      " |      themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  supports_masking\n",
      " |      Whether this layer supports computing a mask using `compute_mask`.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(keras.Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "input_ = np.zeros((10,100,100,3))\n",
    "input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = Input(shape=(100,100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 100, 100, 3) dtype=float32 (created by layer 'input_2')>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 307328) dtype=float32 (created by layer 'flatten_1')>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear1 = layers.Conv2D(32,3,activation='relu')\n",
    "hi = linear1(input_)\n",
    "hi\n",
    "flatten = layers.Flatten()\n",
    "hi = flatten(hi)\n",
    "hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasTensor' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/media/hchang/ssd/hchang/working/programming/Python3/algo/myalgo/lms/test/tensor.ipynb Cell 26'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/hchang/ssd/hchang/working/programming/Python3/algo/myalgo/lms/test/tensor.ipynb#ch0000025?line=0'>1</a>\u001b[0m input_\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m100\u001b[39m,\u001b[39m100\u001b[39m,\u001b[39m3\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KerasTensor' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "input_.reshape(-1,100,100,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = tf.constant(input_.reshape(-1,100,100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = tf.cast(hi,dtype=tf.dtypes.float64)\n",
    "hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1(hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dic = {'hi':['sli','sli','woihg'],'hihi':['skiuh','sliuhe','swliuhe']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hi</th>\n",
       "      <th>hihi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sli</td>\n",
       "      <td>skiuh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sli</td>\n",
       "      <td>sliuhe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>woihg</td>\n",
       "      <td>swliuhe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hi     hihi\n",
       "0    sli    skiuh\n",
       "1    sli   sliuhe\n",
       "2  woihg  swliuhe"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dic)\n",
    "# df.to_dict()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        sliskiuh\n",
       "1       slisliuhe\n",
       "2    woihgswliuhe\n",
       "dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hi'] + df['hihi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hi</th>\n",
       "      <th>hihi</th>\n",
       "      <th>what</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sli</td>\n",
       "      <td>skiuh</td>\n",
       "      <td>ils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sli</td>\n",
       "      <td>sliuhe</td>\n",
       "      <td>ils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>woihg</td>\n",
       "      <td>swliuhe</td>\n",
       "      <td>ghiow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hi     hihi   what\n",
       "0    sli    skiuh    ils\n",
       "1    sli   sliuhe    ils\n",
       "2  woihg  swliuhe  ghiow"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['what'] = df['hi'].apply(f)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(16, 3, activation='relu')\n",
    "        self.maxpool1 = keras.layers.MaxPool2D((2,2))\n",
    "        self.conv2 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.maxpool2 = keras.layers.MaxPool2D((2,2))\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(256, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(100, activation='softmax')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 64s 33ms/step - loss: 0.1801 - accuracy: 0.9470\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 70s 37ms/step - loss: 0.0508 - accuracy: 0.9847\n",
      "Epoch 3/5\n",
      " 362/1875 [====>.........................] - ETA: 56s - loss: 0.0299 - accuracy: 0.9903"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/media/hchang/ssd/hchang/working/programming/Python3/algo/myalgo/lms/test/tensor.ipynb Cell 36'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/hchang/ssd/hchang/working/programming/Python3/algo/myalgo/lms/test/tensor.ipynb#ch0000035?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/hchang/ssd/hchang/working/programming/Python3/algo/myalgo/lms/test/tensor.ipynb#ch0000035?line=1'>2</a>\u001b[0m               loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/hchang/ssd/hchang/working/programming/Python3/algo/myalgo/lms/test/tensor.ipynb#ch0000035?line=2'>3</a>\u001b[0m               metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/hchang/ssd/hchang/working/programming/Python3/algo/myalgo/lms/test/tensor.ipynb#ch0000035?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(x_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/hchang/ssd/hchang/working/programming/Python3/algo/myalgo/lms/test/tensor.ipynb#ch0000035?line=6'>7</a>\u001b[0m model\u001b[39m.\u001b[39mevaluate(x_test,  y_test, verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/myspace/env/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/myspace/env/lib/python3.10/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/myspace/env/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/myspace/env/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/myspace/env/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/myspace/env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/myspace/env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/myspace/env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/myspace/env/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = model.get_layer('conv2d_5')\n",
    "conv._trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'custom_model/conv2d_6/kernel:0' shape=(3, 3, 16, 32) dtype=float32, numpy=\n",
       " array([[[[ 1.25078887e-01,  2.78015248e-02, -2.33017445e-01, ...,\n",
       "           -2.70983964e-01, -1.52706176e-01,  5.37920110e-02],\n",
       "          [-7.56899267e-02,  1.46566376e-01, -1.86523631e-01, ...,\n",
       "           -8.01745281e-02, -7.82550573e-02,  1.14065625e-01],\n",
       "          [-2.52362579e-01,  2.80316379e-02, -8.16269368e-02, ...,\n",
       "           -1.35744736e-01, -3.38280313e-02,  3.53418551e-02],\n",
       "          ...,\n",
       "          [-1.60183877e-01, -2.77104042e-02, -6.57543615e-02, ...,\n",
       "            5.76559305e-02, -3.27024865e-03,  3.95929776e-02],\n",
       "          [-2.54543871e-01,  7.21685737e-02, -5.01246415e-02, ...,\n",
       "           -4.62773107e-02, -1.22082993e-01,  7.83667117e-02],\n",
       "          [ 1.23633355e-01, -9.70052034e-02, -1.47850752e-01, ...,\n",
       "           -3.22059780e-01, -5.59226200e-02, -9.53446925e-02]],\n",
       " \n",
       "         [[ 1.07545041e-01,  2.12029725e-01, -1.70932010e-01, ...,\n",
       "           -1.55104071e-01, -1.59748495e-01,  8.16846788e-02],\n",
       "          [-2.73949839e-02,  1.92446206e-02, -2.46967971e-01, ...,\n",
       "           -1.27838746e-01, -7.51628056e-02, -7.53005221e-02],\n",
       "          [ 3.82053033e-02,  7.81819969e-02, -4.02087718e-02, ...,\n",
       "            1.21159203e-01, -7.53295198e-02,  1.19259898e-02],\n",
       "          ...,\n",
       "          [ 1.68451771e-01,  1.00788735e-01,  9.40068513e-02, ...,\n",
       "           -4.16451804e-02, -2.27581058e-02,  1.20553911e-01],\n",
       "          [ 1.64485171e-01,  1.13812350e-02, -3.43426093e-02, ...,\n",
       "            1.37857914e-01, -1.07584774e-01,  1.31592140e-01],\n",
       "          [ 4.40454595e-02,  2.06819832e-01,  7.86954612e-02, ...,\n",
       "           -1.45932436e-01, -1.73154026e-01,  4.42424193e-02]],\n",
       " \n",
       "         [[-2.28574067e-01,  2.33670399e-01, -3.76792848e-02, ...,\n",
       "           -7.22707212e-02,  3.35122040e-03,  9.07340795e-02],\n",
       "          [ 4.33406085e-02,  2.21860617e-01,  1.03023700e-01, ...,\n",
       "           -1.27070993e-01, -2.18222052e-01, -1.77801587e-02],\n",
       "          [ 9.07423347e-02,  7.90463462e-02, -7.00584128e-02, ...,\n",
       "           -1.43632293e-02,  1.13504212e-02,  1.14452727e-01],\n",
       "          ...,\n",
       "          [ 5.33521585e-02,  1.50799289e-01,  1.70930997e-01, ...,\n",
       "            2.77009103e-02, -1.26015708e-01, -7.11432695e-02],\n",
       "          [ 2.05841120e-02,  1.94817074e-02, -2.44193021e-02, ...,\n",
       "           -4.62758318e-02, -7.90101066e-02,  3.75293903e-02],\n",
       "          [-2.02691346e-01,  6.75113425e-02,  6.85154870e-02, ...,\n",
       "           -1.72899514e-01,  7.68213486e-03, -4.32871133e-02]]],\n",
       " \n",
       " \n",
       "        [[[-1.53588817e-01,  6.47516921e-03,  3.31862859e-04, ...,\n",
       "           -3.30449343e-01, -3.74242455e-01, -9.37323943e-02],\n",
       "          [-1.02858409e-01, -1.11718252e-01, -6.30896389e-02, ...,\n",
       "           -2.23964453e-01, -1.51951715e-01, -9.19340625e-02],\n",
       "          [-1.33788064e-01, -1.37614831e-01,  6.22214787e-02, ...,\n",
       "           -1.70605510e-01,  1.59671362e-02, -1.12368837e-02],\n",
       "          ...,\n",
       "          [-5.71673885e-02,  1.79999042e-02, -1.07552698e-02, ...,\n",
       "            1.26925223e-02, -1.04647294e-01,  4.67644036e-02],\n",
       "          [-7.82627240e-02,  6.04428118e-04, -4.24052067e-02, ...,\n",
       "           -1.47818327e-01, -2.01818243e-01,  3.56657766e-02],\n",
       "          [-9.14304629e-02,  1.50489345e-01, -7.95132816e-02, ...,\n",
       "           -2.10784197e-01, -2.94632733e-01, -2.75462512e-02]],\n",
       " \n",
       "         [[-1.83687866e-01,  2.70244688e-01,  4.59104665e-02, ...,\n",
       "           -1.33257806e-01, -1.72294751e-01, -1.24503992e-01],\n",
       "          [-1.34958535e-01,  1.43623799e-01,  6.35624826e-02, ...,\n",
       "           -6.23593107e-03, -1.70343503e-01,  8.73033628e-02],\n",
       "          [ 6.95686787e-02,  2.43569091e-02,  1.45112395e-01, ...,\n",
       "           -2.30557024e-02,  1.06016979e-01, -6.09305277e-02],\n",
       "          ...,\n",
       "          [ 7.72341415e-02, -2.68545952e-02,  1.35964900e-01, ...,\n",
       "            6.83122948e-02,  2.53118072e-02, -4.07930836e-02],\n",
       "          [ 1.29589766e-01, -6.25325441e-02,  1.24974288e-01, ...,\n",
       "            1.53258443e-03,  8.41176324e-03,  4.71077161e-03],\n",
       "          [-1.29306927e-01,  1.84616640e-01, -8.15134346e-02, ...,\n",
       "           -2.17616647e-01, -1.96376964e-01,  1.13622852e-01]],\n",
       " \n",
       "         [[-1.06386088e-01,  1.97208360e-01,  1.51323751e-01, ...,\n",
       "            2.26152346e-01, -1.67004958e-01, -1.11697838e-01],\n",
       "          [-2.41368532e-01, -1.78090036e-01, -6.23170175e-02, ...,\n",
       "            1.73578873e-01, -1.52119160e-01,  1.35423467e-01],\n",
       "          [-7.76554737e-03,  5.73176555e-02,  1.36436850e-01, ...,\n",
       "           -9.79659259e-02, -1.13341361e-01, -5.46889007e-02],\n",
       "          ...,\n",
       "          [ 4.03792039e-02, -8.50757584e-02, -4.25277948e-02, ...,\n",
       "            5.57653531e-02,  2.28594020e-02,  1.45779818e-01],\n",
       "          [ 6.92347214e-02,  1.72094023e-03,  1.85298368e-01, ...,\n",
       "           -8.10376033e-02, -4.80096042e-02,  1.37761801e-01],\n",
       "          [-2.13291198e-01,  1.49496317e-01,  9.52958837e-02, ...,\n",
       "           -1.11783959e-01, -6.65544048e-02, -8.82014111e-02]]],\n",
       " \n",
       " \n",
       "        [[[-1.76755652e-01,  2.57788241e-01,  9.83215198e-02, ...,\n",
       "           -1.38576731e-01, -3.75860065e-01, -2.36133680e-01],\n",
       "          [-1.11941293e-01,  9.90182608e-02, -6.21146783e-02, ...,\n",
       "           -1.15848184e-01, -3.37217033e-01, -1.57647327e-01],\n",
       "          [-5.87596819e-02, -1.46760270e-01,  1.91653043e-01, ...,\n",
       "           -1.32940844e-01, -9.93315354e-02, -1.46117255e-01],\n",
       "          ...,\n",
       "          [ 7.71682262e-02, -8.35848376e-02,  9.25229490e-02, ...,\n",
       "           -8.12354833e-02, -4.43176627e-02, -8.72037560e-02],\n",
       "          [-5.89138679e-02,  1.73351616e-02,  8.55264515e-02, ...,\n",
       "           -1.50286689e-01, -7.74162337e-02, -1.60969257e-01],\n",
       "          [-3.87500860e-02,  2.38802865e-01, -1.56535413e-02, ...,\n",
       "           -1.19702190e-01, -3.69047731e-01, -2.76707113e-02]],\n",
       " \n",
       "         [[-2.20788479e-01,  2.40885809e-01,  1.07115671e-01, ...,\n",
       "           -1.02690786e-01, -1.18276708e-01, -3.02699298e-01],\n",
       "          [-1.46739110e-01, -5.28639667e-02, -1.34587273e-01, ...,\n",
       "            8.11133906e-03, -9.93590802e-02, -1.70208678e-01],\n",
       "          [ 9.28531215e-02, -8.79268274e-02,  8.92435908e-02, ...,\n",
       "           -4.99363020e-02,  1.58381477e-01,  1.03647843e-01],\n",
       "          ...,\n",
       "          [ 7.10527003e-02, -1.46083608e-01, -9.89916176e-02, ...,\n",
       "           -3.30331661e-02,  5.45878522e-02, -4.06108871e-02],\n",
       "          [-9.43466369e-03, -2.45355554e-02, -8.49961489e-02, ...,\n",
       "            5.69208153e-02,  1.28745109e-01,  7.67003670e-02],\n",
       "          [-1.09971762e-01,  1.02921724e-01, -8.17970634e-02, ...,\n",
       "           -9.83317345e-02, -2.35775948e-01,  1.82987396e-02]],\n",
       " \n",
       "         [[-6.66246563e-02,  2.49487489e-01,  2.17078641e-01, ...,\n",
       "            2.49723587e-02, -1.37386873e-01, -6.07956164e-02],\n",
       "          [-2.52624273e-01, -1.43117622e-01, -1.64226532e-01, ...,\n",
       "            1.05117358e-01,  6.31642295e-03, -1.86584398e-01],\n",
       "          [-7.96336308e-02, -1.92228526e-01, -1.06667645e-01, ...,\n",
       "            5.32928780e-02, -6.18233625e-03,  3.16186398e-02],\n",
       "          ...,\n",
       "          [-2.05964237e-01, -1.45542443e-01, -6.13080598e-02, ...,\n",
       "            1.19393222e-01, -3.94928046e-02, -3.18488516e-02],\n",
       "          [-3.63094267e-03, -1.37560770e-01, -3.27409469e-02, ...,\n",
       "            1.31765672e-03,  7.19048828e-02,  3.18420678e-02],\n",
       "          [-1.88384697e-01,  1.91372693e-01,  2.25438967e-01, ...,\n",
       "            1.41835153e-01, -2.07917973e-01,  4.24088202e-02]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'custom_model/conv2d_6/bias:0' shape=(32,) dtype=float32, numpy=\n",
       " array([-0.00167214, -0.01043835, -0.0301092 , -0.09156576, -0.01308389,\n",
       "        -0.06742818, -0.10729909, -0.02971889, -0.06623375, -0.06455045,\n",
       "        -0.06649955,  0.00347472, -0.11378315, -0.07103624,  0.00068258,\n",
       "        -0.11625076, -0.00766244, -0.17765085,  0.01336755, -0.04078329,\n",
       "        -0.04617271, -0.10906444, -0.10386001, -0.10867168, -0.06787168,\n",
       "        -0.01228227, -0.1266065 , -0.06664325, -0.0971797 , -0.13239598,\n",
       "        -0.01088443, -0.02363185], dtype=float32)>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = model.get_layer('conv2d_6')\n",
    "conv.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'custom_model/conv2d_5/kernel:0' shape=(3, 3, 1, 16) dtype=float32, numpy=\n",
       " array([[[[ 0.1249071 , -0.09342137, -0.10176703,  0.07485765,\n",
       "            0.07001688, -0.21748419,  0.11641727,  0.06741447,\n",
       "           -0.38208207,  0.21259475, -0.00220113,  0.06001128,\n",
       "            0.16883196,  0.03653433, -0.18850005,  0.09117416]],\n",
       " \n",
       "         [[ 0.14599757, -0.3016077 , -0.05793192, -0.00548347,\n",
       "            0.08717285, -0.3176404 ,  0.09715287,  0.24237129,\n",
       "           -0.28123277,  0.22667015,  0.0607455 ,  0.21145354,\n",
       "            0.05839781,  0.11908037, -0.13383837,  0.25074017]],\n",
       " \n",
       "         [[-0.08726311, -0.37464985,  0.16216415, -0.04632605,\n",
       "            0.09925289,  0.06855186,  0.18939793,  0.01981679,\n",
       "            0.09218055,  0.18419614,  0.36855334, -0.22439362,\n",
       "           -0.26508728, -0.21804717, -0.18312201,  0.1288581 ]]],\n",
       " \n",
       " \n",
       "        [[[-0.277027  ,  0.1418704 ,  0.00710752, -0.01144679,\n",
       "           -0.13236894, -0.44407606, -0.18117677, -0.29492888,\n",
       "           -0.20569856,  0.10034537, -0.01855367,  0.17412993,\n",
       "            0.24655798, -0.09310552,  0.0340705 , -0.40724614]],\n",
       " \n",
       "         [[-0.40754572,  0.00613511,  0.32769173,  0.10625678,\n",
       "            0.2897521 ,  0.0361264 ,  0.1264791 ,  0.2566994 ,\n",
       "           -0.04648225, -0.03187459, -0.06601804,  0.18251769,\n",
       "           -0.11080671, -0.11406979,  0.12448294, -0.3741251 ]],\n",
       " \n",
       "         [[-0.20376   ,  0.04737587,  0.1984041 ,  0.14479874,\n",
       "           -0.09462417,  0.1557301 ,  0.22765611,  0.21060427,\n",
       "            0.32962665,  0.14942244,  0.29899174, -0.02325046,\n",
       "           -0.33308712,  0.17951396,  0.22727434, -0.33706334]]],\n",
       " \n",
       " \n",
       "        [[[ 0.19751586,  0.1824802 ,  0.19756101, -0.11908517,\n",
       "           -0.22970502, -0.04445278,  0.03219537, -0.3997236 ,\n",
       "           -0.11950387, -0.37304243, -0.4025231 ,  0.19845597,\n",
       "            0.2953132 ,  0.10036984,  0.26162866,  0.11166156]],\n",
       " \n",
       "         [[ 0.20406847,  0.21530546,  0.1290701 , -0.1132271 ,\n",
       "            0.16889107,  0.12748282,  0.14039852, -0.16369766,\n",
       "            0.09783483, -0.31512716, -0.2875995 ,  0.1484804 ,\n",
       "           -0.00482416,  0.2581173 , -0.0382046 ,  0.04585031]],\n",
       " \n",
       "         [[ 0.24439606,  0.25418603, -0.2785557 ,  0.2571435 ,\n",
       "            0.16759476,  0.30795038,  0.21028228,  0.32571015,\n",
       "            0.3978973 , -0.19710733, -0.05651213,  0.03284604,\n",
       "           -0.04742809,  0.11763604, -0.06478464,  0.08125778]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'custom_model/conv2d_5/bias:0' shape=(16,) dtype=float32, numpy=\n",
       " array([-0.00418878,  0.00022694, -0.06335066, -0.1176602 , -0.07856725,\n",
       "         0.01492854, -0.07676685, -0.09243665,  0.06959028, -0.00944009,\n",
       "        -0.01098642, -0.06269889,  0.00969065, -0.0409456 , -0.00178764,\n",
       "         0.03022926], dtype=float32)>,\n",
       " <tf.Variable 'custom_model/conv2d_6/kernel:0' shape=(3, 3, 16, 32) dtype=float32, numpy=\n",
       " array([[[[ 1.25078887e-01,  2.78015248e-02, -2.33017445e-01, ...,\n",
       "           -2.70983964e-01, -1.52706176e-01,  5.37920110e-02],\n",
       "          [-7.56899267e-02,  1.46566376e-01, -1.86523631e-01, ...,\n",
       "           -8.01745281e-02, -7.82550573e-02,  1.14065625e-01],\n",
       "          [-2.52362579e-01,  2.80316379e-02, -8.16269368e-02, ...,\n",
       "           -1.35744736e-01, -3.38280313e-02,  3.53418551e-02],\n",
       "          ...,\n",
       "          [-1.60183877e-01, -2.77104042e-02, -6.57543615e-02, ...,\n",
       "            5.76559305e-02, -3.27024865e-03,  3.95929776e-02],\n",
       "          [-2.54543871e-01,  7.21685737e-02, -5.01246415e-02, ...,\n",
       "           -4.62773107e-02, -1.22082993e-01,  7.83667117e-02],\n",
       "          [ 1.23633355e-01, -9.70052034e-02, -1.47850752e-01, ...,\n",
       "           -3.22059780e-01, -5.59226200e-02, -9.53446925e-02]],\n",
       " \n",
       "         [[ 1.07545041e-01,  2.12029725e-01, -1.70932010e-01, ...,\n",
       "           -1.55104071e-01, -1.59748495e-01,  8.16846788e-02],\n",
       "          [-2.73949839e-02,  1.92446206e-02, -2.46967971e-01, ...,\n",
       "           -1.27838746e-01, -7.51628056e-02, -7.53005221e-02],\n",
       "          [ 3.82053033e-02,  7.81819969e-02, -4.02087718e-02, ...,\n",
       "            1.21159203e-01, -7.53295198e-02,  1.19259898e-02],\n",
       "          ...,\n",
       "          [ 1.68451771e-01,  1.00788735e-01,  9.40068513e-02, ...,\n",
       "           -4.16451804e-02, -2.27581058e-02,  1.20553911e-01],\n",
       "          [ 1.64485171e-01,  1.13812350e-02, -3.43426093e-02, ...,\n",
       "            1.37857914e-01, -1.07584774e-01,  1.31592140e-01],\n",
       "          [ 4.40454595e-02,  2.06819832e-01,  7.86954612e-02, ...,\n",
       "           -1.45932436e-01, -1.73154026e-01,  4.42424193e-02]],\n",
       " \n",
       "         [[-2.28574067e-01,  2.33670399e-01, -3.76792848e-02, ...,\n",
       "           -7.22707212e-02,  3.35122040e-03,  9.07340795e-02],\n",
       "          [ 4.33406085e-02,  2.21860617e-01,  1.03023700e-01, ...,\n",
       "           -1.27070993e-01, -2.18222052e-01, -1.77801587e-02],\n",
       "          [ 9.07423347e-02,  7.90463462e-02, -7.00584128e-02, ...,\n",
       "           -1.43632293e-02,  1.13504212e-02,  1.14452727e-01],\n",
       "          ...,\n",
       "          [ 5.33521585e-02,  1.50799289e-01,  1.70930997e-01, ...,\n",
       "            2.77009103e-02, -1.26015708e-01, -7.11432695e-02],\n",
       "          [ 2.05841120e-02,  1.94817074e-02, -2.44193021e-02, ...,\n",
       "           -4.62758318e-02, -7.90101066e-02,  3.75293903e-02],\n",
       "          [-2.02691346e-01,  6.75113425e-02,  6.85154870e-02, ...,\n",
       "           -1.72899514e-01,  7.68213486e-03, -4.32871133e-02]]],\n",
       " \n",
       " \n",
       "        [[[-1.53588817e-01,  6.47516921e-03,  3.31862859e-04, ...,\n",
       "           -3.30449343e-01, -3.74242455e-01, -9.37323943e-02],\n",
       "          [-1.02858409e-01, -1.11718252e-01, -6.30896389e-02, ...,\n",
       "           -2.23964453e-01, -1.51951715e-01, -9.19340625e-02],\n",
       "          [-1.33788064e-01, -1.37614831e-01,  6.22214787e-02, ...,\n",
       "           -1.70605510e-01,  1.59671362e-02, -1.12368837e-02],\n",
       "          ...,\n",
       "          [-5.71673885e-02,  1.79999042e-02, -1.07552698e-02, ...,\n",
       "            1.26925223e-02, -1.04647294e-01,  4.67644036e-02],\n",
       "          [-7.82627240e-02,  6.04428118e-04, -4.24052067e-02, ...,\n",
       "           -1.47818327e-01, -2.01818243e-01,  3.56657766e-02],\n",
       "          [-9.14304629e-02,  1.50489345e-01, -7.95132816e-02, ...,\n",
       "           -2.10784197e-01, -2.94632733e-01, -2.75462512e-02]],\n",
       " \n",
       "         [[-1.83687866e-01,  2.70244688e-01,  4.59104665e-02, ...,\n",
       "           -1.33257806e-01, -1.72294751e-01, -1.24503992e-01],\n",
       "          [-1.34958535e-01,  1.43623799e-01,  6.35624826e-02, ...,\n",
       "           -6.23593107e-03, -1.70343503e-01,  8.73033628e-02],\n",
       "          [ 6.95686787e-02,  2.43569091e-02,  1.45112395e-01, ...,\n",
       "           -2.30557024e-02,  1.06016979e-01, -6.09305277e-02],\n",
       "          ...,\n",
       "          [ 7.72341415e-02, -2.68545952e-02,  1.35964900e-01, ...,\n",
       "            6.83122948e-02,  2.53118072e-02, -4.07930836e-02],\n",
       "          [ 1.29589766e-01, -6.25325441e-02,  1.24974288e-01, ...,\n",
       "            1.53258443e-03,  8.41176324e-03,  4.71077161e-03],\n",
       "          [-1.29306927e-01,  1.84616640e-01, -8.15134346e-02, ...,\n",
       "           -2.17616647e-01, -1.96376964e-01,  1.13622852e-01]],\n",
       " \n",
       "         [[-1.06386088e-01,  1.97208360e-01,  1.51323751e-01, ...,\n",
       "            2.26152346e-01, -1.67004958e-01, -1.11697838e-01],\n",
       "          [-2.41368532e-01, -1.78090036e-01, -6.23170175e-02, ...,\n",
       "            1.73578873e-01, -1.52119160e-01,  1.35423467e-01],\n",
       "          [-7.76554737e-03,  5.73176555e-02,  1.36436850e-01, ...,\n",
       "           -9.79659259e-02, -1.13341361e-01, -5.46889007e-02],\n",
       "          ...,\n",
       "          [ 4.03792039e-02, -8.50757584e-02, -4.25277948e-02, ...,\n",
       "            5.57653531e-02,  2.28594020e-02,  1.45779818e-01],\n",
       "          [ 6.92347214e-02,  1.72094023e-03,  1.85298368e-01, ...,\n",
       "           -8.10376033e-02, -4.80096042e-02,  1.37761801e-01],\n",
       "          [-2.13291198e-01,  1.49496317e-01,  9.52958837e-02, ...,\n",
       "           -1.11783959e-01, -6.65544048e-02, -8.82014111e-02]]],\n",
       " \n",
       " \n",
       "        [[[-1.76755652e-01,  2.57788241e-01,  9.83215198e-02, ...,\n",
       "           -1.38576731e-01, -3.75860065e-01, -2.36133680e-01],\n",
       "          [-1.11941293e-01,  9.90182608e-02, -6.21146783e-02, ...,\n",
       "           -1.15848184e-01, -3.37217033e-01, -1.57647327e-01],\n",
       "          [-5.87596819e-02, -1.46760270e-01,  1.91653043e-01, ...,\n",
       "           -1.32940844e-01, -9.93315354e-02, -1.46117255e-01],\n",
       "          ...,\n",
       "          [ 7.71682262e-02, -8.35848376e-02,  9.25229490e-02, ...,\n",
       "           -8.12354833e-02, -4.43176627e-02, -8.72037560e-02],\n",
       "          [-5.89138679e-02,  1.73351616e-02,  8.55264515e-02, ...,\n",
       "           -1.50286689e-01, -7.74162337e-02, -1.60969257e-01],\n",
       "          [-3.87500860e-02,  2.38802865e-01, -1.56535413e-02, ...,\n",
       "           -1.19702190e-01, -3.69047731e-01, -2.76707113e-02]],\n",
       " \n",
       "         [[-2.20788479e-01,  2.40885809e-01,  1.07115671e-01, ...,\n",
       "           -1.02690786e-01, -1.18276708e-01, -3.02699298e-01],\n",
       "          [-1.46739110e-01, -5.28639667e-02, -1.34587273e-01, ...,\n",
       "            8.11133906e-03, -9.93590802e-02, -1.70208678e-01],\n",
       "          [ 9.28531215e-02, -8.79268274e-02,  8.92435908e-02, ...,\n",
       "           -4.99363020e-02,  1.58381477e-01,  1.03647843e-01],\n",
       "          ...,\n",
       "          [ 7.10527003e-02, -1.46083608e-01, -9.89916176e-02, ...,\n",
       "           -3.30331661e-02,  5.45878522e-02, -4.06108871e-02],\n",
       "          [-9.43466369e-03, -2.45355554e-02, -8.49961489e-02, ...,\n",
       "            5.69208153e-02,  1.28745109e-01,  7.67003670e-02],\n",
       "          [-1.09971762e-01,  1.02921724e-01, -8.17970634e-02, ...,\n",
       "           -9.83317345e-02, -2.35775948e-01,  1.82987396e-02]],\n",
       " \n",
       "         [[-6.66246563e-02,  2.49487489e-01,  2.17078641e-01, ...,\n",
       "            2.49723587e-02, -1.37386873e-01, -6.07956164e-02],\n",
       "          [-2.52624273e-01, -1.43117622e-01, -1.64226532e-01, ...,\n",
       "            1.05117358e-01,  6.31642295e-03, -1.86584398e-01],\n",
       "          [-7.96336308e-02, -1.92228526e-01, -1.06667645e-01, ...,\n",
       "            5.32928780e-02, -6.18233625e-03,  3.16186398e-02],\n",
       "          ...,\n",
       "          [-2.05964237e-01, -1.45542443e-01, -6.13080598e-02, ...,\n",
       "            1.19393222e-01, -3.94928046e-02, -3.18488516e-02],\n",
       "          [-3.63094267e-03, -1.37560770e-01, -3.27409469e-02, ...,\n",
       "            1.31765672e-03,  7.19048828e-02,  3.18420678e-02],\n",
       "          [-1.88384697e-01,  1.91372693e-01,  2.25438967e-01, ...,\n",
       "            1.41835153e-01, -2.07917973e-01,  4.24088202e-02]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'custom_model/conv2d_6/bias:0' shape=(32,) dtype=float32, numpy=\n",
       " array([-0.00167214, -0.01043835, -0.0301092 , -0.09156576, -0.01308389,\n",
       "        -0.06742818, -0.10729909, -0.02971889, -0.06623375, -0.06455045,\n",
       "        -0.06649955,  0.00347472, -0.11378315, -0.07103624,  0.00068258,\n",
       "        -0.11625076, -0.00766244, -0.17765085,  0.01336755, -0.04078329,\n",
       "        -0.04617271, -0.10906444, -0.10386001, -0.10867168, -0.06787168,\n",
       "        -0.01228227, -0.1266065 , -0.06664325, -0.0971797 , -0.13239598,\n",
       "        -0.01088443, -0.02363185], dtype=float32)>,\n",
       " <tf.Variable 'custom_model/dense_2/kernel:0' shape=(800, 256) dtype=float32, numpy=\n",
       " array([[ 0.02685562, -0.13785237, -0.0921521 , ..., -0.07542505,\n",
       "         -0.04487735,  0.00928233],\n",
       "        [-0.06792222,  0.05912901,  0.07224569, ..., -0.04230369,\n",
       "          0.05769901, -0.07256626],\n",
       "        [-0.11247518,  0.04676249, -0.05743046, ...,  0.03749044,\n",
       "         -0.07920233, -0.01513847],\n",
       "        ...,\n",
       "        [ 0.0697986 ,  0.01985001,  0.12527001, ..., -0.01935009,\n",
       "          0.06398872, -0.05681337],\n",
       "        [ 0.13784419,  0.03636579,  0.09576487, ...,  0.0064526 ,\n",
       "          0.04397869, -0.05395915],\n",
       "        [-0.00349783,  0.0426035 ,  0.0196817 , ..., -0.07471197,\n",
       "         -0.03161532, -0.01679018]], dtype=float32)>,\n",
       " <tf.Variable 'custom_model/dense_2/bias:0' shape=(256,) dtype=float32, numpy=\n",
       " array([ 0.01131259, -0.01777676,  0.02694723, -0.00064339, -0.00933629,\n",
       "        -0.01062295,  0.02536215, -0.00428214, -0.01901739, -0.00823953,\n",
       "        -0.01101055, -0.02827126, -0.00107562,  0.02911359,  0.00134046,\n",
       "        -0.00970112,  0.01417332,  0.02395071, -0.0025531 , -0.01331191,\n",
       "        -0.00689054, -0.01784148, -0.0106133 ,  0.02082707, -0.01043196,\n",
       "        -0.00668711, -0.00637642, -0.01177587,  0.02373725,  0.00056676,\n",
       "         0.02829773,  0.01687143,  0.01579343, -0.0146303 ,  0.01312237,\n",
       "        -0.0226853 ,  0.01302641, -0.00843651,  0.04006599,  0.02195395,\n",
       "        -0.0129496 ,  0.01176867,  0.02801892,  0.02805014, -0.03206379,\n",
       "        -0.02577257,  0.0090934 , -0.00883608, -0.02156606, -0.01658451,\n",
       "         0.00571677,  0.01780813,  0.00520681,  0.01255459,  0.02717546,\n",
       "         0.02420782, -0.00634959, -0.01754185,  0.00436445,  0.03149743,\n",
       "        -0.02704807, -0.02041801,  0.03318293, -0.00666725,  0.00958764,\n",
       "         0.00010321, -0.00921885,  0.02761116,  0.03361702, -0.01897072,\n",
       "        -0.00535785,  0.00061882,  0.05290224, -0.00203929, -0.01567876,\n",
       "         0.01487665,  0.00599361, -0.01226537, -0.01433969, -0.0101875 ,\n",
       "        -0.03824938,  0.03509224,  0.00398738, -0.02364148, -0.01933736,\n",
       "        -0.00613445,  0.01025011,  0.04482385,  0.02716539, -0.01631862,\n",
       "        -0.02527871,  0.01820254, -0.01199747,  0.00993715,  0.01674229,\n",
       "        -0.02403147, -0.00937762, -0.00878052, -0.01148299, -0.01684544,\n",
       "         0.02407089,  0.01328271,  0.04503373, -0.0150026 , -0.00787856,\n",
       "        -0.01815888, -0.01731412, -0.01416652,  0.00684302, -0.02057972,\n",
       "        -0.01171719,  0.00967144,  0.00291265,  0.01225126, -0.02268075,\n",
       "        -0.01229577,  0.03122058,  0.02707626,  0.01102474, -0.00719555,\n",
       "         0.00770764, -0.00822453,  0.03493455, -0.00743725, -0.00562739,\n",
       "        -0.01341322, -0.00818608,  0.02684897, -0.01229238,  0.01621676,\n",
       "        -0.01604724,  0.01879852, -0.0125153 , -0.01045676, -0.01438983,\n",
       "        -0.03770079,  0.04294952,  0.02873384,  0.00934717,  0.01538197,\n",
       "         0.02115554, -0.01082757,  0.02586861, -0.01379239, -0.01071046,\n",
       "         0.03785055, -0.00892148, -0.00913304, -0.01707943,  0.04991686,\n",
       "        -0.00252686, -0.04410489, -0.00962215, -0.00960504,  0.03211869,\n",
       "        -0.05848284,  0.032852  , -0.00538812, -0.00676127, -0.01277745,\n",
       "         0.00689809,  0.00517727, -0.02132947, -0.00531854, -0.00540763,\n",
       "         0.01261219, -0.02670979, -0.00871093,  0.00411388,  0.01497887,\n",
       "         0.03707399,  0.02924624, -0.01878119,  0.01549629, -0.0070654 ,\n",
       "        -0.01752528,  0.00101761,  0.01591723, -0.00831083, -0.01622224,\n",
       "         0.01513776,  0.04173299, -0.02909556, -0.00231168,  0.02074466,\n",
       "         0.01270567, -0.02907146,  0.01586162, -0.02570267, -0.00904738,\n",
       "        -0.06009421, -0.02808048,  0.00164668,  0.00747313, -0.01189745,\n",
       "        -0.00937352,  0.01276983,  0.02173256, -0.00930748,  0.00770206,\n",
       "         0.01113917,  0.01469318, -0.01106447,  0.02186879, -0.01871415,\n",
       "        -0.00562796,  0.03950257,  0.04258927, -0.03407651,  0.00020982,\n",
       "        -0.04943642, -0.01664426, -0.01224186,  0.00233347, -0.01652307,\n",
       "         0.01655448, -0.00721977, -0.00551257, -0.02786089, -0.01601975,\n",
       "        -0.01384003,  0.01319768,  0.01390095, -0.00295829, -0.02432954,\n",
       "        -0.04713433,  0.02641358, -0.01914018, -0.01098358,  0.0041021 ,\n",
       "        -0.00782268,  0.01069659, -0.01136812,  0.00368278, -0.04471133,\n",
       "         0.03923271, -0.00682378,  0.04268463, -0.00759408,  0.04130604,\n",
       "        -0.01600415,  0.02113049,  0.02151963,  0.0259873 ,  0.0066542 ,\n",
       "         0.03165679, -0.0099436 , -0.03130406,  0.02451122, -0.00766013,\n",
       "        -0.00572186, -0.0280805 , -0.01426044, -0.02412444, -0.01190471,\n",
       "         0.02612782], dtype=float32)>,\n",
       " <tf.Variable 'custom_model/dense_3/kernel:0' shape=(256, 100) dtype=float32, numpy=\n",
       " array([[-0.03204142, -0.00370993, -0.06055638, ..., -0.05545167,\n",
       "          0.02880762, -0.09903937],\n",
       "        [ 0.03122898, -0.09083187,  0.02579269, ..., -0.11469742,\n",
       "         -0.14096415, -0.25038967],\n",
       "        [-0.10570218,  0.12012396,  0.11130997, ...,  0.05376389,\n",
       "         -0.15896013, -0.05278499],\n",
       "        ...,\n",
       "        [ 0.11359888, -0.11288379,  0.01323977, ..., -0.08478579,\n",
       "         -0.09375308,  0.07152344],\n",
       "        [-0.06018756,  0.00835589, -0.0476216 , ...,  0.04912558,\n",
       "          0.07811492, -0.07576305],\n",
       "        [ 0.03240103,  0.0726188 ,  0.0162073 , ...,  0.09836853,\n",
       "         -0.03016292, -0.12875944]], dtype=float32)>,\n",
       " <tf.Variable 'custom_model/dense_3/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([ 0.03013053,  0.03397007,  0.02318119,  0.03442334,  0.00335407,\n",
       "         0.01965009,  0.00215052,  0.02608538, -0.00674681, -0.00669037,\n",
       "        -0.01850436, -0.02054527, -0.01846224, -0.02053811, -0.02198969,\n",
       "        -0.01895495, -0.02176378, -0.01972475, -0.02033255, -0.02107916,\n",
       "        -0.02043564, -0.02025952, -0.02261487, -0.0188283 , -0.02077706,\n",
       "        -0.0211452 , -0.01879066, -0.02235517, -0.02301445, -0.02270289,\n",
       "        -0.01931114, -0.02093463, -0.02142112, -0.02129016, -0.02131596,\n",
       "        -0.0179497 , -0.02018437, -0.02166296, -0.02105747, -0.02033715,\n",
       "        -0.01955443, -0.02389601, -0.02097844, -0.02158833, -0.023111  ,\n",
       "        -0.01901083, -0.02011339, -0.02142753, -0.01912631, -0.02167664,\n",
       "        -0.02098535, -0.0203362 , -0.02348232, -0.01865746, -0.01910342,\n",
       "        -0.01947329, -0.01986347, -0.01919465, -0.01991976, -0.02163932,\n",
       "        -0.01840335, -0.02170951, -0.02049654, -0.02062984, -0.02111761,\n",
       "        -0.0193039 , -0.01869826, -0.02113313, -0.02022488, -0.02230957,\n",
       "        -0.02089293, -0.01848414, -0.02130415, -0.02122416, -0.02169083,\n",
       "        -0.02324229, -0.02096069, -0.02039727, -0.02126536, -0.02053069,\n",
       "        -0.02125117, -0.02185949, -0.02168041, -0.02258855, -0.0223513 ,\n",
       "        -0.02073794, -0.01942515, -0.01887578, -0.02008139, -0.02050645,\n",
       "        -0.01991015, -0.02011614, -0.02153921, -0.02118798, -0.02055966,\n",
       "        -0.01691959, -0.02121804, -0.02162544, -0.02179797, -0.01979882],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'custom_model/conv2d_5/kernel:0' shape=(3, 3, 1, 16) dtype=float32, numpy=\n",
       " array([[[[ 0.1249071 , -0.09342137, -0.10176703,  0.07485765,\n",
       "            0.07001688, -0.21748419,  0.11641727,  0.06741447,\n",
       "           -0.38208207,  0.21259475, -0.00220113,  0.06001128,\n",
       "            0.16883196,  0.03653433, -0.18850005,  0.09117416]],\n",
       " \n",
       "         [[ 0.14599757, -0.3016077 , -0.05793192, -0.00548347,\n",
       "            0.08717285, -0.3176404 ,  0.09715287,  0.24237129,\n",
       "           -0.28123277,  0.22667015,  0.0607455 ,  0.21145354,\n",
       "            0.05839781,  0.11908037, -0.13383837,  0.25074017]],\n",
       " \n",
       "         [[-0.08726311, -0.37464985,  0.16216415, -0.04632605,\n",
       "            0.09925289,  0.06855186,  0.18939793,  0.01981679,\n",
       "            0.09218055,  0.18419614,  0.36855334, -0.22439362,\n",
       "           -0.26508728, -0.21804717, -0.18312201,  0.1288581 ]]],\n",
       " \n",
       " \n",
       "        [[[-0.277027  ,  0.1418704 ,  0.00710752, -0.01144679,\n",
       "           -0.13236894, -0.44407606, -0.18117677, -0.29492888,\n",
       "           -0.20569856,  0.10034537, -0.01855367,  0.17412993,\n",
       "            0.24655798, -0.09310552,  0.0340705 , -0.40724614]],\n",
       " \n",
       "         [[-0.40754572,  0.00613511,  0.32769173,  0.10625678,\n",
       "            0.2897521 ,  0.0361264 ,  0.1264791 ,  0.2566994 ,\n",
       "           -0.04648225, -0.03187459, -0.06601804,  0.18251769,\n",
       "           -0.11080671, -0.11406979,  0.12448294, -0.3741251 ]],\n",
       " \n",
       "         [[-0.20376   ,  0.04737587,  0.1984041 ,  0.14479874,\n",
       "           -0.09462417,  0.1557301 ,  0.22765611,  0.21060427,\n",
       "            0.32962665,  0.14942244,  0.29899174, -0.02325046,\n",
       "           -0.33308712,  0.17951396,  0.22727434, -0.33706334]]],\n",
       " \n",
       " \n",
       "        [[[ 0.19751586,  0.1824802 ,  0.19756101, -0.11908517,\n",
       "           -0.22970502, -0.04445278,  0.03219537, -0.3997236 ,\n",
       "           -0.11950387, -0.37304243, -0.4025231 ,  0.19845597,\n",
       "            0.2953132 ,  0.10036984,  0.26162866,  0.11166156]],\n",
       " \n",
       "         [[ 0.20406847,  0.21530546,  0.1290701 , -0.1132271 ,\n",
       "            0.16889107,  0.12748282,  0.14039852, -0.16369766,\n",
       "            0.09783483, -0.31512716, -0.2875995 ,  0.1484804 ,\n",
       "           -0.00482416,  0.2581173 , -0.0382046 ,  0.04585031]],\n",
       " \n",
       "         [[ 0.24439606,  0.25418603, -0.2785557 ,  0.2571435 ,\n",
       "            0.16759476,  0.30795038,  0.21028228,  0.32571015,\n",
       "            0.3978973 , -0.19710733, -0.05651213,  0.03284604,\n",
       "           -0.04742809,  0.11763604, -0.06478464,  0.08125778]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'custom_model/conv2d_5/bias:0' shape=(16,) dtype=float32, numpy=\n",
       " array([-0.00418878,  0.00022694, -0.06335066, -0.1176602 , -0.07856725,\n",
       "         0.01492854, -0.07676685, -0.09243665,  0.06959028, -0.00944009,\n",
       "        -0.01098642, -0.06269889,  0.00969065, -0.0409456 , -0.00178764,\n",
       "         0.03022926], dtype=float32)>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.non_trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossfunc = tf.keras.losses.SparseCategoricalCrossentropy() + 100\n",
    "optimizer = tf.keras.optimizers.Adagrad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.eager.backprop.GradientTape object at 0x7f73d7bfd340>\n",
      "<class 'tensorflow.python.eager.backprop.GradientTape'>\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    prediction = model(x_test[:5])\n",
    "    loss = lossfunc(y_test[:5],prediction)\n",
    "    gradients = tape.gradient(loss,model.trainable_variables)\n",
    "    print(tape)\n",
    "    print(type(tape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=9.280365e-05>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(3, 3, 16, 32), dtype=float32, numpy=\n",
       " array([[[[ 3.53207383e-08, -4.78679576e-05, -5.95983965e-06, ...,\n",
       "           -1.20810600e-05, -2.36422466e-07,  2.11602355e-07],\n",
       "          [ 7.61394858e-09, -3.23368877e-05,  4.59060885e-07, ...,\n",
       "            1.91003187e-06, -1.88888578e-07,  3.56259989e-07],\n",
       "          [ 2.07319317e-08, -3.52601601e-05,  1.69797261e-06, ...,\n",
       "           -1.26978011e-06, -5.61274817e-07,  5.57184535e-07],\n",
       "          ...,\n",
       "          [ 2.44233433e-08, -5.21468355e-05, -2.89246827e-07, ...,\n",
       "           -2.11161455e-06, -1.80134577e-07,  1.09647090e-07],\n",
       "          [-3.54165763e-07, -5.98258339e-05, -7.58038514e-05, ...,\n",
       "           -2.32283528e-05, -9.85999213e-06,  1.35954806e-05],\n",
       "          [ 5.54389885e-08, -4.84212724e-05, -3.59678197e-05, ...,\n",
       "           -1.56738934e-05, -7.56505585e-07,  4.74171975e-06]],\n",
       " \n",
       "         [[ 3.98292066e-08, -1.68873194e-05, -6.03292792e-05, ...,\n",
       "           -1.49052994e-05, -4.66495976e-06,  7.70961469e-06],\n",
       "          [ 1.45222572e-07, -3.18224556e-05, -5.37739179e-05, ...,\n",
       "           -1.57173963e-05, -6.93408674e-06,  1.16608817e-05],\n",
       "          [ 1.88779907e-07, -1.50728183e-05, -3.45804474e-05, ...,\n",
       "           -1.17698346e-05, -9.67282813e-06,  1.01418345e-05],\n",
       "          ...,\n",
       "          [-2.12319009e-07, -2.73060723e-05, -6.49986614e-05, ...,\n",
       "           -1.69471150e-05, -7.43027840e-06,  1.56796632e-05],\n",
       "          [ 1.73138244e-06, -3.20860181e-07, -3.92703296e-05, ...,\n",
       "            1.56140891e-06, -3.54704462e-05, -7.82551615e-06],\n",
       "          [ 2.44404159e-08, -7.97292887e-06, -5.27159282e-05, ...,\n",
       "           -1.21153798e-05, -1.93301021e-05,  5.18586967e-06]],\n",
       " \n",
       "         [[ 2.38362460e-07, -4.23838628e-07, -2.06664663e-06, ...,\n",
       "            7.29737508e-07, -2.20112088e-05, -1.20766508e-05],\n",
       "          [-3.64867617e-07, -6.87152010e-07, -1.01098558e-05, ...,\n",
       "            2.19861795e-06, -2.07240482e-05, -2.92729555e-06],\n",
       "          [ 1.47051958e-06, -1.04895889e-07, -1.17650325e-06, ...,\n",
       "           -1.30785196e-07, -1.20380073e-05, -1.08419199e-05],\n",
       "          ...,\n",
       "          [ 1.12397356e-06, -6.67598442e-07, -6.47837533e-06, ...,\n",
       "            1.19138508e-06, -2.54836741e-05, -1.03587508e-05],\n",
       "          [-7.96028985e-08, -2.71501222e-08, -2.72848411e-12, ...,\n",
       "           -2.43062209e-06, -1.53774563e-05, -3.80523011e-06],\n",
       "          [ 8.56812676e-07, -1.70884277e-07, -4.53924486e-07, ...,\n",
       "           -3.82595346e-07, -1.90533556e-05, -1.35418341e-05]]],\n",
       " \n",
       " \n",
       "        [[[ 1.18498633e-08, -5.44599461e-05, -4.42393612e-05, ...,\n",
       "           -1.82121821e-05, -2.90007938e-06,  6.76363516e-06],\n",
       "          [ 3.04761897e-07, -5.32780286e-05, -1.28398078e-05, ...,\n",
       "           -6.86973362e-06, -1.13675321e-06,  2.24546079e-06],\n",
       "          [ 1.72774946e-06, -3.71560200e-05, -2.05394153e-05, ...,\n",
       "           -7.73257307e-06, -3.66956829e-06,  4.55990084e-06],\n",
       "          ...,\n",
       "          [ 1.20191999e-08, -6.19935454e-05, -3.81720893e-05, ...,\n",
       "           -1.60681957e-05, -3.88726221e-07,  3.45754006e-06],\n",
       "          [ 4.93485459e-07, -4.94773412e-05, -8.18216795e-05, ...,\n",
       "           -1.91928466e-05, -3.31679112e-05,  1.91286781e-05],\n",
       "          [ 6.32272872e-07, -4.90536040e-05, -5.39928878e-05, ...,\n",
       "           -1.58041130e-05, -9.19374361e-06,  1.90992359e-05]],\n",
       " \n",
       "         [[-7.09402002e-07, -2.90694561e-06, -4.91105748e-05, ...,\n",
       "           -8.93065771e-06, -3.38869868e-05,  8.85152076e-06],\n",
       "          [-1.84421617e-06, -1.10671062e-05, -5.45313887e-05, ...,\n",
       "           -1.18997505e-05, -2.51661186e-05,  1.60074051e-05],\n",
       "          [ 4.26680174e-07, -4.28766452e-06, -3.61670172e-05, ...,\n",
       "           -7.73825923e-06, -3.14831923e-05,  1.02835220e-05],\n",
       "          ...,\n",
       "          [-1.33128117e-06, -1.00668349e-05, -5.53361970e-05, ...,\n",
       "           -1.15804432e-05, -3.57566751e-05,  1.28923875e-05],\n",
       "          [ 3.58671036e-06, -1.39854706e-09, -9.78569187e-06, ...,\n",
       "           -3.33283708e-07, -4.74838234e-05, -1.60608797e-05],\n",
       "          [ 1.70654846e-06, -1.67038479e-06, -3.24622961e-05, ...,\n",
       "           -5.78443451e-06, -4.28433195e-05,  7.01011459e-06]],\n",
       " \n",
       "         [[ 4.95165659e-06, -1.02534159e-07, -7.02636953e-08, ...,\n",
       "           -2.33260471e-06, -1.85825957e-05, -1.11072968e-05],\n",
       "          [ 3.79518042e-06,  1.05429990e-07,  1.75066020e-07, ...,\n",
       "           -1.07379799e-06, -2.45362844e-05, -1.47955943e-05],\n",
       "          [ 4.69582892e-06,  1.25641748e-07,  8.29131636e-07, ...,\n",
       "           -2.53936855e-06, -1.82354252e-05, -9.80575169e-06],\n",
       "          ...,\n",
       "          [ 6.12067561e-06, -1.02904778e-07, -4.92383492e-07, ...,\n",
       "           -1.82623785e-06, -2.71265344e-05, -1.86684792e-05],\n",
       "          [-1.94416657e-06,  3.21288098e-08, -1.24790063e-08, ...,\n",
       "           -3.44190539e-06, -1.92161792e-06, -4.74836997e-06],\n",
       "          [ 3.68198653e-06,  4.22439541e-08, -3.25601377e-08, ...,\n",
       "           -3.74808997e-06, -1.13043452e-05, -6.80986432e-06]]],\n",
       " \n",
       " \n",
       "        [[[ 5.49274887e-07, -5.06086144e-05, -6.00257990e-05, ...,\n",
       "           -8.26624637e-06, -1.13998085e-05,  2.58238324e-05],\n",
       "          [ 5.54998337e-07, -5.16321561e-05, -3.96412361e-05, ...,\n",
       "           -1.07909163e-05, -7.88223247e-07,  1.07617198e-05],\n",
       "          [ 2.67971643e-07, -2.96160742e-05, -3.47879468e-05, ...,\n",
       "            2.28566932e-06, -2.74126683e-06,  1.06427160e-05],\n",
       "          ...,\n",
       "          [ 4.03557010e-07, -5.41133486e-05, -5.53036734e-05, ...,\n",
       "           -4.89762988e-06, -3.29086515e-06,  2.60460019e-05],\n",
       "          [ 5.27376505e-06, -1.59881929e-05, -8.48880009e-05, ...,\n",
       "           -1.26005070e-05, -5.59704713e-05,  2.19145732e-05],\n",
       "          [ 3.74538195e-06, -3.52747738e-05, -5.71895544e-05, ...,\n",
       "           -6.88559885e-06, -2.79214619e-05,  2.28521330e-05]],\n",
       " \n",
       "         [[ 7.24208621e-06, -4.48835671e-08, -1.98230919e-05, ...,\n",
       "            1.96585597e-06, -4.78741495e-05,  9.25277982e-06],\n",
       "          [ 1.09224572e-06, -2.69339034e-06, -3.64817097e-05, ...,\n",
       "            1.03774300e-06, -4.45177284e-05,  1.50574588e-05],\n",
       "          [ 1.73820081e-06, -4.40460497e-07, -1.96892488e-05, ...,\n",
       "            4.68750113e-06, -3.75365853e-05,  1.36128765e-05],\n",
       "          ...,\n",
       "          [ 4.99891030e-06, -1.77608285e-07, -3.60216291e-05, ...,\n",
       "            5.24361076e-06, -5.74957230e-05,  1.64472294e-05],\n",
       "          [ 9.76706247e-07, -2.92733290e-07,  2.59128365e-06, ...,\n",
       "            1.09383950e-06, -4.15956602e-05, -1.38049691e-05],\n",
       "          [ 7.99071495e-06, -1.14471050e-07, -1.33243457e-05, ...,\n",
       "            1.19237697e-07, -4.54486544e-05,  3.91385583e-06]],\n",
       " \n",
       "         [[ 3.39201006e-06,  2.91950073e-08, -3.00587999e-10, ...,\n",
       "           -3.40881979e-06, -5.45846069e-06, -2.08922461e-06],\n",
       "          [ 2.83613531e-06, -1.40450993e-08,  8.52670382e-07, ...,\n",
       "           -2.27292730e-06, -1.76921494e-05, -3.99216697e-06],\n",
       "          [ 2.50564995e-07, -6.64792424e-07, -6.09386802e-07, ...,\n",
       "           -1.95462212e-06, -6.97361702e-06, -5.35774177e-07],\n",
       "          ...,\n",
       "          [ 1.69973464e-06, -8.24456947e-09,  8.57116220e-07, ...,\n",
       "           -3.45273907e-06, -1.53716173e-05, -1.22110521e-06],\n",
       "          [-2.05240804e-06, -5.68916221e-08, -3.65813349e-07, ...,\n",
       "           -2.02162482e-07, -4.54747351e-12, -2.43140994e-06],\n",
       "          [ 1.52399741e-06, -1.22339316e-07, -5.51120934e-07, ...,\n",
       "           -3.02171520e-06, -1.99259557e-06, -4.42601618e-07]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
       " array([ 7.60157764e-06, -1.11793874e-04, -1.18455660e-04, -1.78294984e-04,\n",
       "        -2.59425142e-05, -8.45228715e-06,  8.82003519e-08, -4.64394288e-05,\n",
       "         6.07821348e-05, -1.21991843e-05,  8.50841971e-05,  1.30342087e-05,\n",
       "         4.06391700e-06,  1.11674693e-04,  1.22070400e-04,  1.02446094e-04,\n",
       "        -8.53525635e-05, -1.08625809e-05, -2.52472470e-04, -1.15840803e-05,\n",
       "         5.47689633e-05, -3.42648418e-05,  0.00000000e+00, -1.32703799e-05,\n",
       "         2.11513343e-05, -7.35628855e-05, -1.51557433e-05, -7.10282548e-05,\n",
       "         2.12991336e-06, -2.83716181e-05, -1.00963982e-04,  2.15888504e-05],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(800, 256), dtype=float32, numpy=\n",
       " array([[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "         -4.5891446e-09,  0.0000000e+00,  1.1292262e-11],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        ...,\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  3.3930789e-08, ...,\n",
       "         -1.4772640e-07,  0.0000000e+00, -6.3927878e-08],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  2.0376390e-11]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(256,), dtype=float32, numpy=\n",
       " array([ 0.00000000e+00,  0.00000000e+00,  2.13977164e-05, -2.51407655e-05,\n",
       "        -4.91288756e-06, -1.68883219e-08, -2.99254748e-06,  4.15813020e-08,\n",
       "         8.13479073e-06, -1.04148319e-06,  0.00000000e+00,  1.77014920e-06,\n",
       "         1.12326359e-06, -8.35970150e-06,  1.20333636e-08, -1.66108543e-06,\n",
       "         0.00000000e+00,  0.00000000e+00, -2.05546930e-05,  0.00000000e+00,\n",
       "        -9.70342353e-06, -1.58517437e-07,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -9.10652943e-06, -8.56050337e-06, -1.99031160e-06,\n",
       "        -9.97524239e-06, -2.49370544e-07,  0.00000000e+00,  0.00000000e+00,\n",
       "        -2.73363696e-07,  8.34915568e-07, -5.39059556e-07,  0.00000000e+00,\n",
       "        -2.03645468e-05,  0.00000000e+00, -2.97274460e-06, -0.00000000e+00,\n",
       "         1.69312693e-06,  5.10948485e-06,  0.00000000e+00,  4.93898096e-06,\n",
       "         2.61792138e-07,  1.07235974e-05,  0.00000000e+00,  4.26224278e-06,\n",
       "         0.00000000e+00,  6.95780614e-07, -1.17627233e-05, -3.31154610e-07,\n",
       "        -2.28288864e-05,  0.00000000e+00, -8.41175279e-06, -3.34338552e-06,\n",
       "         0.00000000e+00,  5.17520220e-07,  2.85347778e-06, -5.63300409e-06,\n",
       "        -1.25059569e-06,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -1.87898422e-06, -5.73483794e-06,  3.47521313e-06,  0.00000000e+00,\n",
       "         0.00000000e+00, -2.55840459e-05,  0.00000000e+00,  7.79982543e-07,\n",
       "         2.06466102e-05, -5.88413172e-07,  1.71497766e-06, -3.86128534e-07,\n",
       "        -3.78026402e-06,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -1.35763935e-06, -4.71485066e-07,  4.78876336e-06,\n",
       "         4.82955556e-07,  0.00000000e+00,  9.13978784e-06,  1.06630487e-05,\n",
       "        -3.41667319e-11,  0.00000000e+00,  0.00000000e+00, -2.06218501e-05,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.38490589e-06,  0.00000000e+00,\n",
       "         6.61061677e-06,  5.37322364e-08, -7.08474499e-06,  1.33560407e-05,\n",
       "        -5.90945547e-06,  0.00000000e+00, -2.20504899e-06,  1.08583897e-07,\n",
       "         0.00000000e+00, -2.12652736e-07,  3.10611927e-06,  0.00000000e+00,\n",
       "         4.85144801e-06,  0.00000000e+00,  7.06954282e-08, -4.18155651e-06,\n",
       "         0.00000000e+00,  2.34984185e-07, -9.32185912e-07, -5.85160706e-06,\n",
       "         0.00000000e+00, -3.37256438e-06,  0.00000000e+00, -6.62437606e-06,\n",
       "        -5.46429828e-06,  1.57288369e-07, -4.99176713e-06,  0.00000000e+00,\n",
       "         1.13595746e-07,  0.00000000e+00,  1.72030977e-05,  0.00000000e+00,\n",
       "        -1.43994112e-05,  1.34035918e-05, -1.93951291e-05, -1.23638602e-05,\n",
       "        -2.86691579e-06,  1.14512404e-05,  1.67474373e-05, -9.80726418e-06,\n",
       "         0.00000000e+00,  1.27962430e-05,  1.20584491e-06, -0.00000000e+00,\n",
       "         1.02255426e-05, -1.81526605e-06,  1.08429354e-07,  4.63091556e-06,\n",
       "         0.00000000e+00,  4.26208942e-07, -1.73983676e-06,  0.00000000e+00,\n",
       "        -1.58827297e-05,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -4.80304561e-06,  0.00000000e+00, -1.82204744e-07, -2.40271106e-07,\n",
       "        -2.00946218e-07, -2.40605146e-07,  0.00000000e+00, -2.00974159e-06,\n",
       "        -5.94774993e-11,  0.00000000e+00, -3.80103160e-07,  0.00000000e+00,\n",
       "        -2.20200195e-06, -8.18905210e-06,  0.00000000e+00, -2.18355353e-06,\n",
       "         0.00000000e+00,  0.00000000e+00, -5.73965735e-07, -5.74580781e-07,\n",
       "         8.34172988e-06, -3.39246043e-07, -1.71793522e-06,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -2.78527041e-05,\n",
       "        -1.57910763e-05,  3.45497313e-07, -1.08977770e-06,  2.24972355e-05,\n",
       "         0.00000000e+00, -5.77924948e-06,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -1.23557243e-07,  0.00000000e+00,  0.00000000e+00,\n",
       "         6.70420661e-07,  0.00000000e+00,  6.54069663e-06,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  9.86128634e-06,\n",
       "         0.00000000e+00, -2.09265363e-06,  3.98832753e-07, -1.84028813e-05,\n",
       "        -2.82917972e-05, -5.79172092e-06, -2.35627140e-05, -9.43116163e-07,\n",
       "        -1.69106585e-07, -2.77921226e-05, -1.37737075e-07,  0.00000000e+00,\n",
       "        -3.14279191e-07,  0.00000000e+00, -3.17417107e-06,  1.97353003e-07,\n",
       "         0.00000000e+00,  9.29695216e-06,  2.71357294e-07, -9.15156761e-06,\n",
       "         2.38408546e-08, -5.47607715e-06, -2.35310672e-05, -3.41828581e-07,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -2.33456205e-07,\n",
       "         1.41745631e-05,  0.00000000e+00,  9.06084239e-08,  0.00000000e+00,\n",
       "        -7.06837545e-06,  0.00000000e+00,  0.00000000e+00, -1.83651027e-05,\n",
       "        -3.04663729e-07, -6.29275655e-06, -1.69118880e-06, -3.62383389e-07,\n",
       "         0.00000000e+00,  0.00000000e+00, -2.22097292e-08,  3.79583344e-06,\n",
       "         0.00000000e+00,  0.00000000e+00, -7.14903126e-06, -3.70103123e-07,\n",
       "         6.31535158e-07, -1.54591464e-06,  1.61486491e-06,  3.77964859e-09,\n",
       "         0.00000000e+00, -2.28020303e-06,  0.00000000e+00, -1.65690821e-07],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(256, 100), dtype=float32, numpy=\n",
       " array([[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [-7.2346356e-06, -3.1154407e-06,  2.8974634e-06, ...,\n",
       "          3.1046105e-12,  4.3075803e-12,  5.2772899e-12],\n",
       "        ...,\n",
       "        [-1.7732333e-07, -2.7357370e-05,  3.3085675e-07, ...,\n",
       "          1.9948156e-12,  1.5961886e-12,  3.7791030e-13],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [-3.0312503e-06,  9.7039066e-10,  1.2059435e-06, ...,\n",
       "          6.8245583e-13,  8.4418757e-13,  1.9693984e-12]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(100,), dtype=float32, numpy=\n",
       " array([-2.99663998e-06, -6.81871243e-05,  1.60325953e-06,  1.10838675e-06,\n",
       "         3.85750936e-05,  9.90402498e-08,  4.99780799e-06,  1.60504283e-06,\n",
       "         2.84505495e-06,  2.03961154e-05,  1.04618319e-11,  5.37890609e-12,\n",
       "         3.05086165e-12,  1.52432721e-12,  7.26673669e-12,  1.72218045e-12,\n",
       "         9.42378814e-12,  4.87623527e-12,  3.28457769e-12,  2.41529583e-12,\n",
       "         2.38804072e-12,  2.88388627e-12,  1.68784821e-12,  8.71003682e-13,\n",
       "         1.39704676e-12,  2.89508955e-12,  2.39838596e-12,  4.29586054e-12,\n",
       "         5.50285165e-12,  4.27542854e-12,  4.55234505e-12,  4.67631446e-12,\n",
       "         6.89057362e-12,  2.52753157e-12,  5.23461656e-12,  2.44317587e-12,\n",
       "         1.50835572e-12,  3.63869958e-12,  1.73927474e-12,  3.65719477e-12,\n",
       "         1.89944154e-12,  4.53394917e-12,  6.18603736e-12,  3.13365176e-12,\n",
       "         1.60113307e-12,  3.57819894e-12,  5.35933884e-12,  4.76302071e-12,\n",
       "         3.19696570e-12,  8.04738275e-13,  4.46890875e-12,  2.42498751e-12,\n",
       "         4.14595528e-12,  3.56506101e-12,  4.14654509e-12,  1.90962003e-12,\n",
       "         4.26345851e-12,  2.46953001e-12,  6.29429451e-12,  2.52171786e-12,\n",
       "         2.38774278e-12,  2.77735929e-12,  2.45367875e-12,  2.86314592e-12,\n",
       "         3.70136994e-12,  1.31504345e-12,  1.55659047e-12,  2.36943061e-12,\n",
       "         5.66026262e-12,  4.28350281e-12,  5.00607542e-12,  1.77307192e-12,\n",
       "         3.10860278e-12,  5.37669735e-12,  4.96351961e-12,  2.94122517e-12,\n",
       "         2.56789013e-12,  2.15978212e-12,  3.60848764e-12,  5.72414945e-12,\n",
       "         2.40242201e-12,  5.05117692e-12,  3.90740435e-12,  2.31570275e-12,\n",
       "         5.63475091e-12,  3.23550193e-12,  3.81279860e-12,  1.49296081e-12,\n",
       "         5.42504366e-12,  1.32797965e-11,  3.44245444e-12,  4.78934037e-12,\n",
       "         1.90115176e-12,  1.38661912e-12,  7.43071750e-12,  2.47461817e-12,\n",
       "         2.65934540e-12,  5.57776698e-12,  4.98804296e-12,  2.63765247e-12],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a39879ae9ccb927afc0cf2ce944a9e89e93d1a75059893b60dcfa8646ca8faf1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
